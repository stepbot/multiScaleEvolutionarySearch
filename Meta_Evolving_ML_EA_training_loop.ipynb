{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stepbot/multiScaleEvolutionarySearch/blob/master/Meta_Evolving_ML_EA_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Meta-Evolving Genetic Algorithm Operators with LLMs (V2)\n",
        "\n",
        "This script implements a meta-evolutionary algorithm where the core evolutionary\n",
        "operator itself is evolved by an LLM.\n",
        "\n",
        "Instead of evolving separate 'crossover' and 'mutate' functions, we evolve a\n",
        "single, holistic function: `generate_next_population`. This function takes the\n",
        "current population and their fitness scores and is responsible for producing\n",
        "the entire next generation.\n",
        "\n",
        "This approach gives the LLM maximum creative freedom to discover novel\n",
        "evolutionary strategies, potentially departing from traditional GA structures.\n",
        "\"\"\"\n",
        "\n",
        "# @title 1. Install Dependencies\n",
        "!pip install -q -U google-generativeai openai tqdm matplotlib\n",
        "\n",
        "# @title 2. Setup and Imports\n",
        "import google.generativeai as genai\n",
        "import openai\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "import textwrap\n",
        "from IPython.display import Markdown, display\n",
        "import itertools\n",
        "import os\n",
        "import traceback\n",
        "\n",
        "# @title 3. Configure LLM APIs\n",
        "# @markdown Add your API keys to the Colab secrets manager (key icon on the left).\n",
        "# @markdown - `GOOGLE_API_KEY` for Gemini\n",
        "# @markdown - `OPENAI_API_KEY` for OpenAI\n",
        "# @markdown The script will use any and all configured clients.\n",
        "\n",
        "llm_clients = []\n",
        "\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    # Configure Gemini\n",
        "    GOOGLE_API_KEY = userdata.get('gemini_key')\n",
        "    if GOOGLE_API_KEY:\n",
        "        genai.configure(api_key=GOOGLE_API_KEY)\n",
        "        # Use the updated model name here\n",
        "        llm_clients.append(genai.GenerativeModel('gemini-2.5-pro'))\n",
        "        print(\"✅ Successfully configured and added Gemini client.\")\n",
        "\n",
        "        # --- Debug: List available Gemini models ---\n",
        "        print(\"\\n--- Available Gemini Models (for 'generateContent') ---\")\n",
        "        # The genai.list_models() function gets all models\n",
        "        for m in genai.list_models():\n",
        "            if 'generateContent' in m.supported_generation_methods:\n",
        "                print(m.name)\n",
        "        print(\"-----------------------------------------------------\\n\")\n",
        "        # --- End Debug ---\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ Warning: GOOGLE_API_KEY not found in Colab secrets. Gemini client will not be used.\")\n",
        "\n",
        "    # Configure OpenAI\n",
        "    OPENAI_API_KEY = userdata.get('openai_key')\n",
        "    if OPENAI_API_KEY:\n",
        "        # It's good practice to set the env variable for some libraries\n",
        "        os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "        openai_client = openai.OpenAI() # Create a client instance first\n",
        "        llm_clients.append(openai_client)\n",
        "        print(\"✅ Successfully configured and added OpenAI client.\")\n",
        "\n",
        "        # --- Debug: List available OpenAI models ---\n",
        "        print(\"\\n--- Available OpenAI Models (GPT models) ---\")\n",
        "        try:\n",
        "            # The client.models.list() function gets all models\n",
        "            model_list = [m.id for m in openai_client.models.list() if 'gpt' in m.id.lower()]\n",
        "            for model_name in sorted(model_list):\n",
        "                print(model_name)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not retrieve OpenAI models: {e}\")\n",
        "        print(\"-------------------------------------------\\n\")\n",
        "        # --- End Debug ---\n",
        "\n",
        "    else:\n",
        "        print(\"⚠️ Warning: OPENAI_API_KEY not found in Colab secrets. OpenAI client will not be used.\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"❌ Could not import userdata. Please run this in a Google Colab environment and add API keys to secrets.\")\n",
        "\n",
        "def call_llm_api(client, prompt, model_name_gemini='gemini-2.5-pro', model_name_openai='gpt-5'):\n",
        "    \"\"\"A unified function to call either Gemini or OpenAI API.\"\"\"\n",
        "    client_name = client.__class__.__module__.split('.')[0]\n",
        "    if client_name == 'google':\n",
        "        model = genai.GenerativeModel(model_name_gemini)\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    elif client_name == 'openai':\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name_openai,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that only returns Python code.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown client type: {client_name}\")\n",
        "\n",
        "\n",
        "# @title 4. Define the Machine Learning Problem (Inner Loop)\n",
        "\n",
        "# --- Configuration ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "INPUT_SIZE = 28 * 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "# --- Model Architecture ---\n",
        "class SimpleNet(nn.Module):\n",
        "    \"\"\"A simple MLP suitable for MNIST, used in the inner GA.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE, 256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(128, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, INPUT_SIZE)\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "# --- Data Loading & Evaluation ---\n",
        "def get_data_loaders():\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    return train_loader, test_loader\n",
        "\n",
        "def evaluate_nn_model(model, loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "\n",
        "# @title 5. Define the Meta-Evolutionary Algorithm (Outer Loop)\n",
        "\n",
        "class OperatorIndividual:\n",
        "    \"\"\"\n",
        "    Represents a single evolutionary operator, now with detailed,\n",
        "    multi-run, per-generation performance history.\n",
        "    \"\"\"\n",
        "    def __init__(self, evolution_operator_code):\n",
        "        self.evolution_operator_code = evolution_operator_code\n",
        "        self.run_histories = [] # Stores detailed history from multiple runs\n",
        "        self.fitness = 0.0      # A single representative score for sorting/selection\n",
        "\n",
        "    def update_history(self, new_run_histories):\n",
        "        \"\"\"Adds new run histories and recalculates the primary fitness score.\"\"\"\n",
        "        if not new_run_histories:\n",
        "            return\n",
        "        self.run_histories.extend(new_run_histories)\n",
        "        self._calculate_primary_fitness()\n",
        "\n",
        "    def _calculate_primary_fitness(self):\n",
        "        \"\"\"\n",
        "        Calculates a single fitness score for elitism and selection.\n",
        "        We define this as the average of the 'best' fitness from the\n",
        "        final generation of each run. This rewards operators that\n",
        "        consistently produce high-performing individuals.\n",
        "        \"\"\"\n",
        "        if not self.run_histories:\n",
        "            self.fitness = 0.0\n",
        "            return\n",
        "\n",
        "        final_bests = [run[-1]['best'] for run in self.run_histories if run]\n",
        "        if final_bests:\n",
        "            self.fitness = sum(final_bests) / len(final_bests)\n",
        "        else:\n",
        "            self.fitness = 0.0\n",
        "\n",
        "    def get_performance_summary_text(self):\n",
        "        \"\"\"\n",
        "        Processes the detailed run histories into a clean, averaged,\n",
        "        human-readable summary table for the LLM prompt.\n",
        "        \"\"\"\n",
        "        if not self.run_histories:\n",
        "            return \"This is a new operator that has not been evaluated yet. Your goal is to create a strong initial version.\"\n",
        "\n",
        "        # Average the stats across all runs to create a single, clear time-series\n",
        "        num_runs = len(self.run_histories)\n",
        "        # Ensure all runs have the same number of generations\n",
        "        if not all(len(run) == len(self.run_histories[0]) for run in self.run_histories):\n",
        "             return \"Error: Inconsistent history data.\"\n",
        "        num_gens = len(self.run_histories[0])\n",
        "\n",
        "        avg_history = [{\"best\": 0.0, \"avg\": 0.0, \"worst\": 0.0} for _ in range(num_gens)]\n",
        "\n",
        "        for run in self.run_histories:\n",
        "            for i in range(num_gens):\n",
        "                avg_history[i][\"best\"] += run[i][\"best\"]\n",
        "                avg_history[i][\"avg\"] += run[i][\"avg\"]\n",
        "                avg_history[i][\"worst\"] += run[i][\"worst\"]\n",
        "\n",
        "        summary_lines = [\n",
        "            f\"This operator's performance has been recorded over **{num_runs}** separate runs.\",\n",
        "            \"The table below shows the fitness dynamics, **averaged across all runs**.\",\n",
        "            \"Fitness is based on the negative loss on training batches (higher is better).\\n\",\n",
        "            \"| Gen | Best Fitness | Avg Fitness  | Worst Fitness | Spread (Diversity) |\",\n",
        "            \"|:---:|:------------:|:------------:|:-------------:|:------------------:|\",\n",
        "        ]\n",
        "\n",
        "        for i in range(num_gens):\n",
        "            gen_stats = avg_history[i]\n",
        "            avg_best = gen_stats['best'] / num_runs\n",
        "            avg_avg = gen_stats['avg'] / num_runs\n",
        "            avg_worst = gen_stats['worst'] / num_runs\n",
        "            spread = avg_best - avg_worst\n",
        "            summary_lines.append(f\"| {i:^3} | {avg_best:12.4f} | {avg_avg:12.4f} | {avg_worst:13.4f} | {spread:18.4f} |\")\n",
        "\n",
        "        summary_lines.extend([\n",
        "            \"\\n**Analysis Hints for Your Evolution:**\",\n",
        "            \"- **Rate of Improvement:** Analyze the slope of the `Best Fitness` column. A steep, consistent increase is ideal.\",\n",
        "            \"- **Population Diversity:** The `Spread (Best-Worst)` column is a proxy for diversity. If it collapses to near-zero too quickly, the population has prematurely converged, and you should consider changes that increase exploration (e.g., higher mutation, different selection).\",\n",
        "            \"- **Stability:** Smooth, predictable improvements indicate a stable operator. Jagged or erratic values might suggest the operator is too chaotic.\"\n",
        "        ])\n",
        "\n",
        "        return \"\\n\".join(summary_lines)\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Provides a compact summary for console logging.\"\"\"\n",
        "        if not self.run_histories:\n",
        "            return f\"Fitness: Not yet evaluated\\n--- Operator Code ---\\n{self.evolution_operator_code}\"\n",
        "        return (f\"Overall Fitness (Avg Final Best): {self.fitness:.4f}\\n\"\n",
        "                f\"Evaluated over {len(self.run_histories)} runs.\\n\"\n",
        "                f\"--- Operator Code ---\\n{self.evolution_operator_code}\")\n",
        "\n",
        "\n",
        "def selection(population, tournament_size=3):\n",
        "    \"\"\"Selects a parent from the population using tournament selection based on its primary fitness score.\"\"\"\n",
        "    if len(population) < tournament_size:\n",
        "        return random.choice(population)\n",
        "    tournament = random.sample(population, tournament_size)\n",
        "    # The 'fitness' attribute now represents consistent high performance\n",
        "    tournament.sort(key=lambda x: x.fitness, reverse=True)\n",
        "    return tournament[0]\n",
        "\n",
        "def llm_evolve_operator(operator_individual, clients):\n",
        "    \"\"\"Uses a randomly selected LLM client to evolve the evolutionary operator, providing detailed generational feedback.\"\"\"\n",
        "    if not clients:\n",
        "        print(\"Warning: No LLM clients configured. Returning original operator.\")\n",
        "        return OperatorIndividual(operator_individual.evolution_operator_code)\n",
        "\n",
        "    client = random.choice(clients)\n",
        "    client_name = client.__class__.__module__.split('.')[0]\n",
        "\n",
        "    # ✨ NEW: Generate the detailed performance summary ✨\n",
        "    performance_feedback = operator_individual.get_performance_summary_text()\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert in genetic algorithms. Your task is to evolve a Python function that acts as a holistic evolutionary operator.\n",
        "This function, `generate_next_population`, is the complete engine of a genetic algorithm, responsible for selection, crossover, and mutation to create the next generation of neural networks.\n",
        "\n",
        "**Performance Feedback:**\n",
        "{performance_feedback}\n",
        "\n",
        "Based on these detailed generational dynamics, your goal is to generate a new, improved version of the operator code.\n",
        "- If the operator shows **good, stable improvement**, consider a subtle refinement.\n",
        "- If the operator **stagnates or converges too fast** (low spread), consider changes that increase exploration or diversity.\n",
        "- If the operator is **unstable or performs poorly**, a more radical change to the evolutionary strategy might be needed.\n",
        "\n",
        "The function signature MUST BE `def generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):`.\n",
        "It must return a new list of models of the same size as the input population.\n",
        "\n",
        "**Current Operator Code:**\n",
        "```python\n",
        "{operator_individual.evolution_operator_code}\n",
        "```\n",
        "Return only the Python code block for the new, evolved function. Do not include explanations or markdown formatting.\n",
        "\"\"\"\n",
        "    try:\n",
        "        print(f\"--- Calling {client_name.capitalize()} API to evolve operator (with generational feedback) ---\")\n",
        "        if client_name == 'google':\n",
        "            # Updated model name for best performance\n",
        "            model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "            response = model.generate_content(prompt)\n",
        "            evolved_code = response.text\n",
        "        elif client_name == 'openai':\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-5\", # Use a strong model for this complex task\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that only returns Python code.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "            )\n",
        "            evolved_code = response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: API call to {client_name.capitalize()} failed: {e}. Returning original operator.\")\n",
        "\n",
        "    return OperatorIndividual(evolved_code)\n",
        "\n",
        "def repair_operator_with_llm(faulty_code, error_trace, clients):\n",
        "    \"\"\"\n",
        "    Attempts to repair a faulty evolutionary operator using an LLM.\n",
        "    \"\"\"\n",
        "    if not clients:\n",
        "        print(\"Warning: No LLM clients configured. Cannot repair operator.\")\n",
        "        return faulty_code\n",
        "\n",
        "    client = random.choice(clients)\n",
        "    client_name = client.__class__.__module__.split('.')[0]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert Python programmer specializing in genetic algorithms. The following Python code for a `generate_next_population` function has failed with an error.\n",
        "\n",
        "Your task is to analyze the code and the stack trace to identify the bug and provide a corrected version of the function.\n",
        "\n",
        "**Faulty Code:**\n",
        "```python\n",
        "{faulty_code}\n",
        "```\n",
        "\n",
        "**Error Stack Trace:**\n",
        "```\n",
        "{error_trace}\n",
        "```\n",
        "\n",
        "Please provide only the corrected Python code block for the function. Do not include explanations or markdown formatting.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        print(f\"--- Calling {client_name.capitalize()} API to repair operator ---\")\n",
        "        if client_name == 'google':\n",
        "            model = genai.GenerativeModel('gemini-2.5-pro')\n",
        "            response = model.generate_content(prompt)\n",
        "            repaired_code = response.text\n",
        "        elif client_name == 'openai':\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-5\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant that only returns Python code.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "            )\n",
        "            repaired_code = response.choices[0].message.content\n",
        "\n",
        "        return repaired_code\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: API call to {client_name.capitalize()} for repair failed: {e}. Returning original faulty code.\")\n",
        "        return faulty_code\n",
        "\n",
        "def create_initial_operator_population(size, clients):\n",
        "    \"\"\"\n",
        "    Creates a diverse first generation of operators.\n",
        "    It starts with one seed function and uses the LLM to generate variations for the rest.\n",
        "    \"\"\"\n",
        "    print(f\"Creating a diverse initial population of size {size} using the LLM...\")\n",
        "\n",
        "    # The seed function remains the same standard GA\n",
        "    initial_evolution_code = \"\"\"\n",
        "\n",
        "def generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n",
        "    '''\n",
        "    A standard Genetic Algorithm implementation for generating the next population.\n",
        "    It uses elitism, tournament selection, uniform crossover, and reset mutation.\n",
        "    '''\n",
        "    POPULATION_SIZE = len(current_population)\n",
        "    ELITISM_RATE = 0.05\n",
        "    TOURNAMENT_SIZE = 5\n",
        "\n",
        "    # --- Helper: Crossover ---\n",
        "    def crossover(parent1, parent2, device):\n",
        "        child = SimpleNet().to(device)\n",
        "        parent1_dict = parent1.state_dict()\n",
        "        parent2_dict = parent2.state_dict()\n",
        "        child_dict = child.state_dict()\n",
        "        for key in parent1_dict.keys():\n",
        "            mask = torch.randint(0, 2, size=parent1_dict[key].shape, device=device).float()\n",
        "            child_dict[key] = (parent1_dict[key] * mask) + (parent2_dict[key] * (1 - mask))\n",
        "        child.load_state_dict(child_dict)\n",
        "        return child\n",
        "\n",
        "    # --- Helper: Mutate ---\n",
        "    def mutate(model, device):\n",
        "        MUTATION_RESET_PROB = 0.00001\n",
        "        with torch.no_grad():\n",
        "            for param in model.parameters():\n",
        "                mask = torch.rand_like(param.data) < MUTATION_RESET_PROB\n",
        "                new_weights = torch.randn_like(param.data)\n",
        "                param.data[mask] = new_weights[mask]\n",
        "        return model\n",
        "\n",
        "    # --- Helper: Tournament Selection ---\n",
        "    def tournament_selection(population, scores):\n",
        "        tournament_indices = torch.randint(0, len(population), (TOURNAMENT_SIZE,))\n",
        "        winner_idx = tournament_indices[torch.argmax(scores[tournament_indices])]\n",
        "        return population[winner_idx]\n",
        "\n",
        "    # --- Main Generation Logic ---\n",
        "    sorted_indices = torch.argsort(fitness_scores, descending=True)\n",
        "    num_elite = int(POPULATION_SIZE * ELITISM_RATE)\n",
        "    new_population = [current_population[i] for i in sorted_indices[:num_elite]]\n",
        "\n",
        "    num_children_to_create = POPULATION_SIZE - num_elite\n",
        "    for _ in range(num_children_to_create):\n",
        "        parent1 = tournament_selection(current_population, fitness_scores)\n",
        "        parent2 = tournament_selection(current_population, fitness_scores)\n",
        "        child = crossover(parent1, parent2, device)\n",
        "        child = mutate(child, device)\n",
        "        new_population.append(child)\n",
        "\n",
        "    return new_population\n",
        "\"\"\"\n",
        "    # Create the first individual from the seed code\n",
        "    seed_individual = OperatorIndividual(initial_evolution_code)\n",
        "\n",
        "    # Initialize the population with the seed\n",
        "    population = [seed_individual]\n",
        "\n",
        "    # Use the LLM to generate the rest of the initial population for diversity\n",
        "    if size > 1:\n",
        "        print(f\"Generating {size - 1} initial variations from the seed operator...\")\n",
        "        # A progress bar is helpful here since this involves multiple API calls\n",
        "        for _ in tqdm(range(size - 1), desc=\"Bootstrapping Initial Population\"):\n",
        "            evolved_individual = llm_evolve_operator(seed_individual, clients)\n",
        "            population.append(evolved_individual)\n",
        "\n",
        "    print(\"Initial population created.\")\n",
        "    return population\n",
        "\n",
        "def selection(population, tournament_size=3):\n",
        "    \"\"\"Selects a parent from the population using tournament selection.\"\"\"\n",
        "    if len(population) < tournament_size:\n",
        "        return random.choice(population)\n",
        "    tournament = random.sample(population, tournament_size)\n",
        "    tournament.sort(key=lambda x: x.fitness, reverse=True)\n",
        "    return tournament[0]\n",
        "\n",
        "\n",
        "# @title 6. Fitness Evaluation: Running the Inner GA\n",
        "def run_inner_ga_for_fitness(operator_individual, train_loader, test_loader,clients):\n",
        "    \"\"\"\n",
        "    Evaluates an OperatorIndividual by running a GA using its evolved operator.\n",
        "    This version captures detailed per-generation statistics (best, avg, worst fitness)\n",
        "    for each run to analyze the operator's behavior over time.\n",
        "    \"\"\"\n",
        "    # --- Parameters ---\n",
        "    NUM_EVAL_RUNS = 3 # Run the inner GA 3 times to average out randomness\n",
        "    # --- Inner GA Parameters ---\n",
        "    POPULATION_SIZE = 50\n",
        "    GENERATIONS = 10\n",
        "    BATCHES_PER_GENERATION = 5\n",
        "    MAX_REPAIR_ATTEMPTS = 1\n",
        "    for attempt in range(MAX_REPAIR_ATTEMPTS + 1):\n",
        "        try:\n",
        "            local_scope = {}\n",
        "            exec(operator_individual.evolution_operator_code, {}, local_scope)\n",
        "            generate_next_population_fn = local_scope['generate_next_population']\n",
        "            # If exec is successful, break the loop\n",
        "            break\n",
        "        except Exception as e:\n",
        "            if attempt < MAX_REPAIR_ATTEMPTS:\n",
        "                print(f\"Error executing evolved code. Attempting LLM repair ({attempt + 1}/{MAX_REPAIR_ATTEMPTS}).\")\n",
        "                error_trace = traceback.format_exc()\n",
        "                repaired_code = repair_operator_with_llm(operator_individual.evolution_operator_code, error_trace, clients)\n",
        "                operator_individual.evolution_operator_code = repaired_code\n",
        "            else:\n",
        "                print(f\"Error executing evolved code after repair attempts: {e}\")\n",
        "                return None # Return None on final failure\n",
        "\n",
        "    all_runs_histories = []\n",
        "    print(f\"Starting {NUM_EVAL_RUNS} detailed evaluation runs for this operator...\")\n",
        "\n",
        "    for run_num in range(NUM_EVAL_RUNS):\n",
        "        print(f\"  > Run {run_num + 1}/{NUM_EVAL_RUNS}...\")\n",
        "        # --- Inner GA Execution ---\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        population = [SimpleNet().to(DEVICE) for _ in range(POPULATION_SIZE)]\n",
        "        streams = [torch.cuda.Stream() for _ in range(POPULATION_SIZE)] if torch.cuda.is_available() else []\n",
        "        train_iterator = iter(itertools.cycle(train_loader))\n",
        "\n",
        "        run_history = []\n",
        "\n",
        "        for generation in range(GENERATIONS):\n",
        "            fitness_scores = torch.zeros(POPULATION_SIZE, device=DEVICE)\n",
        "            for _ in range(BATCHES_PER_GENERATION):\n",
        "                images, labels = next(train_iterator)\n",
        "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "                with torch.no_grad():\n",
        "                    if torch.cuda.is_available():\n",
        "                        for i, model in enumerate(population):\n",
        "                            with torch.cuda.stream(streams[i]):\n",
        "                                outputs = model(images)\n",
        "                                loss = loss_fn(outputs, labels)\n",
        "                                fitness_scores[i] += -loss # Fitness is negative loss\n",
        "                    else: # CPU fallback\n",
        "                         for i, model in enumerate(population):\n",
        "                            outputs = model(images)\n",
        "                            loss = loss_fn(outputs, labels)\n",
        "                            fitness_scores[i] += -loss\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "\n",
        "            # ✨ NEW: Track detailed stats for this generation ✨\n",
        "            best_fitness_gen = fitness_scores.max().item()\n",
        "            worst_fitness_gen = fitness_scores.min().item()\n",
        "            avg_fitness_gen = fitness_scores.mean().item()\n",
        "            run_history.append({\n",
        "                \"generation\": generation,\n",
        "                \"best\": best_fitness_gen,\n",
        "                \"avg\": avg_fitness_gen,\n",
        "                \"worst\": worst_fitness_gen\n",
        "            })\n",
        "\n",
        "            # --- Evolve the population using the LLM's operator ---\n",
        "            population = generate_next_population_fn(population, fitness_scores, DEVICE, torch, SimpleNet)\n",
        "\n",
        "        all_runs_histories.append(run_history)\n",
        "\n",
        "        # We calculate final test accuracy to report progress, but it is NOT the primary fitness metric.\n",
        "        # The generational dynamics (run_history) are the key feedback for the LLM.\n",
        "        best_model = population[torch.argmax(fitness_scores)]\n",
        "        final_acc = evaluate_nn_model(best_model, test_loader)\n",
        "        print(f\"    Run {run_num + 1} finished. Final test accuracy of best model: {final_acc:.2f}%\")\n",
        "\n",
        "    # The detailed history is now the primary output of the evaluation\n",
        "    return all_runs_histories\n",
        "\n",
        "\n",
        "# @title 7. Run the Main Meta-Evolutionary Loop\n",
        "def main():\n",
        "    \"\"\"The main function to run the outer (meta) EA.\"\"\"\n",
        "    if not llm_clients:\n",
        "        print(\"Fatal: No LLM clients were configured. Please add API keys to Colab secrets and restart the runtime.\")\n",
        "        return\n",
        "\n",
        "    # --- Meta-EA Parameters ---\n",
        "    META_POPULATION_SIZE = 6\n",
        "    META_GENERATIONS = 4\n",
        "    MUTATION_RATE = 0.5\n",
        "\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"Warning: CUDA not available. This script is very slow on CPU.\")\n",
        "\n",
        "    train_loader, test_loader = get_data_loaders()\n",
        "\n",
        "    operator_population = create_initial_operator_population(META_POPULATION_SIZE, llm_clients)\n",
        "\n",
        "    for gen in range(META_GENERATIONS):\n",
        "        print(f\"\\n{'='*25} META-GENERATION {gen + 1}/{META_GENERATIONS} {'='*25}\")\n",
        "        print(\"Evolving the `generate_next_population` operator...\")\n",
        "\n",
        "        for i, individual in enumerate(operator_population):\n",
        "                # Only evaluate individuals that have no history\n",
        "                if not individual.run_histories:\n",
        "                    print(f\"\\n--- Evaluating Operator Individual {i+1}/{META_POPULATION_SIZE} ---\")\n",
        "                    display(Markdown(f\"```python\\n{individual.evolution_operator_code}\\n```\"))\n",
        "                    # The function now returns a list of detailed run histories\n",
        "                    new_histories = run_inner_ga_for_fitness(individual, train_loader, test_loader, llm_clients)\n",
        "\n",
        "                    if new_histories is None:\n",
        "                        # Assign negative infinity fitness on failure\n",
        "                        individual.fitness = -float('inf')\n",
        "                        print(f\"Finished evaluation. Operator {i+1} failed and was assigned a fitness of -inf.\")\n",
        "                    else:\n",
        "                        # Use the new method to update the individual's history and fitness\n",
        "                        individual.update_history(new_histories)\n",
        "                        print(f\"Finished evaluation. Operator {i+1} primary fitness: {individual.fitness:.4f}\")\n",
        "\n",
        "        # Sort by the primary fitness metric for elitism\n",
        "        operator_population.sort(key=lambda x: x.fitness, reverse=True)\n",
        "\n",
        "        print(f\"\\n--- Meta-Generation {gen+1} Results ---\")\n",
        "        best_op = operator_population[0]\n",
        "        print(f\"Best Operator Fitness (Avg Final Best): {best_op.fitness:.4f}\")\n",
        "        print(\"Best Performing Operator's Code:\")\n",
        "        display(Markdown(f\"```python\\n{best_op.evolution_operator_code}\\n```\"))\n",
        "        print(\"Best Operator's Performance Summary:\")\n",
        "        display(Markdown(best_op.get_performance_summary_text()))\n",
        "\n",
        "\n",
        "        next_generation = []\n",
        "        next_generation.append(best_op) # Elitism\n",
        "\n",
        "        while len(next_generation) < META_POPULATION_SIZE:\n",
        "            parent = selection(operator_population)\n",
        "            if random.random() < MUTATION_RATE:\n",
        "                child = llm_evolve_operator(parent, llm_clients)\n",
        "            else:\n",
        "                # If not mutating, create a fresh copy with the parent's history\n",
        "                child = OperatorIndividual(parent.evolution_operator_code)\n",
        "                child.run_histories = parent.run_histories[:] # Copy history\n",
        "                child.fitness = parent.fitness\n",
        "            next_generation.append(child)\n",
        "\n",
        "        operator_population = next_generation\n",
        "\n",
        "    print(\"\\nMeta-Evolution finished!\")\n",
        "    print(\"Final Best Performing Operator:\")\n",
        "    display(Markdown(str(operator_population[0])))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e7360983c7504728aa521b2a8c68f143",
            "7d0701252a3a4c73ba84f1afd8182314",
            "e00b041aa1a4408882311a2d025bf91c",
            "e6f10bba14134769be497b813516a182",
            "302f049cfa3249dfb2dae5d7e51421d4",
            "df720add88c7426eac965739a3feb526",
            "88b7883395ff4ec2afce1ad73e2f8237",
            "7006b67ed3144f9cab998c0ae64632f3",
            "93cc2c0ac8e742479a1ab6ddf44761d6",
            "f63c89513f0f46b58b4403982d09088f",
            "46f7da57172a4529b36128ab3247e9f4"
          ]
        },
        "id": "ERYD0PlYVHWG",
        "outputId": "3a3b3e0f-3b72-4a84-97b3-8cd300732d1b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m951.0/951.0 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Successfully configured and added Gemini client.\n",
            "\n",
            "--- Available Gemini Models (for 'generateContent') ---\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-1.5-pro-002\n",
            "models/gemini-1.5-pro\n",
            "models/gemini-1.5-flash-latest\n",
            "models/gemini-1.5-flash\n",
            "models/gemini-1.5-flash-002\n",
            "models/gemini-1.5-flash-8b\n",
            "models/gemini-1.5-flash-8b-001\n",
            "models/gemini-1.5-flash-8b-latest\n",
            "models/gemini-2.5-pro-preview-03-25\n",
            "models/gemini-2.5-flash-preview-05-20\n",
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-flash-lite-preview-06-17\n",
            "models/gemini-2.5-pro-preview-05-06\n",
            "models/gemini-2.5-pro-preview-06-05\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-preview-image-generation\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-2.0-pro-exp\n",
            "models/gemini-2.0-pro-exp-02-05\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.0-flash-thinking-exp-01-21\n",
            "models/gemini-2.0-flash-thinking-exp\n",
            "models/gemini-2.0-flash-thinking-exp-1219\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/learnlm-2.0-flash-experimental\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "-----------------------------------------------------\n",
            "\n",
            "✅ Successfully configured and added OpenAI client.\n",
            "\n",
            "--- Available OpenAI Models (GPT models) ---\n",
            "chatgpt-4o-latest\n",
            "gpt-3.5-turbo\n",
            "gpt-3.5-turbo-0125\n",
            "gpt-3.5-turbo-1106\n",
            "gpt-3.5-turbo-16k\n",
            "gpt-3.5-turbo-instruct\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "gpt-4\n",
            "gpt-4-0125-preview\n",
            "gpt-4-0613\n",
            "gpt-4-1106-preview\n",
            "gpt-4-turbo\n",
            "gpt-4-turbo-2024-04-09\n",
            "gpt-4-turbo-preview\n",
            "gpt-4.1\n",
            "gpt-4.1-2025-04-14\n",
            "gpt-4.1-mini\n",
            "gpt-4.1-mini-2025-04-14\n",
            "gpt-4.1-nano\n",
            "gpt-4.1-nano-2025-04-14\n",
            "gpt-4o\n",
            "gpt-4o-2024-05-13\n",
            "gpt-4o-2024-08-06\n",
            "gpt-4o-2024-11-20\n",
            "gpt-4o-audio-preview\n",
            "gpt-4o-audio-preview-2024-10-01\n",
            "gpt-4o-audio-preview-2024-12-17\n",
            "gpt-4o-audio-preview-2025-06-03\n",
            "gpt-4o-mini\n",
            "gpt-4o-mini-2024-07-18\n",
            "gpt-4o-mini-audio-preview\n",
            "gpt-4o-mini-audio-preview-2024-12-17\n",
            "gpt-4o-mini-realtime-preview\n",
            "gpt-4o-mini-realtime-preview-2024-12-17\n",
            "gpt-4o-mini-search-preview\n",
            "gpt-4o-mini-search-preview-2025-03-11\n",
            "gpt-4o-mini-transcribe\n",
            "gpt-4o-mini-tts\n",
            "gpt-4o-realtime-preview\n",
            "gpt-4o-realtime-preview-2024-10-01\n",
            "gpt-4o-realtime-preview-2024-12-17\n",
            "gpt-4o-realtime-preview-2025-06-03\n",
            "gpt-4o-search-preview\n",
            "gpt-4o-search-preview-2025-03-11\n",
            "gpt-4o-transcribe\n",
            "gpt-5\n",
            "gpt-5-2025-08-07\n",
            "gpt-5-chat-latest\n",
            "gpt-5-mini\n",
            "gpt-5-mini-2025-08-07\n",
            "gpt-5-nano\n",
            "gpt-5-nano-2025-08-07\n",
            "gpt-audio\n",
            "gpt-audio-2025-08-28\n",
            "gpt-image-1\n",
            "gpt-realtime\n",
            "gpt-realtime-2025-08-28\n",
            "-------------------------------------------\n",
            "\n",
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 509kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.70MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.25MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a diverse initial population of size 6 using the LLM...\n",
            "Generating 5 initial variations from the seed operator...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Bootstrapping Initial Population:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7360983c7504728aa521b2a8c68f143"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "--- Calling Google API to evolve operator (with generational feedback) ---\n",
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "Initial population created.\n",
            "\n",
            "========================= META-GENERATION 1/4 =========================\n",
            "Evolving the `generate_next_population` operator...\n",
            "\n",
            "--- Evaluating Operator Individual 1/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\n\n\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    '''\n    A standard Genetic Algorithm implementation for generating the next population.\n    It uses elitism, tournament selection, uniform crossover, and reset mutation.\n    '''\n    POPULATION_SIZE = len(current_population)\n    ELITISM_RATE = 0.05\n    TOURNAMENT_SIZE = 5\n\n    # --- Helper: Crossover ---\n    def crossover(parent1, parent2, device):\n        child = SimpleNet().to(device)\n        parent1_dict = parent1.state_dict()\n        parent2_dict = parent2.state_dict()\n        child_dict = child.state_dict()\n        for key in parent1_dict.keys():\n            mask = torch.randint(0, 2, size=parent1_dict[key].shape, device=device).float()\n            child_dict[key] = (parent1_dict[key] * mask) + (parent2_dict[key] * (1 - mask))\n        child.load_state_dict(child_dict)\n        return child\n\n    # --- Helper: Mutate ---\n    def mutate(model, device):\n        MUTATION_RESET_PROB = 0.00001\n        with torch.no_grad():\n            for param in model.parameters():\n                mask = torch.rand_like(param.data) < MUTATION_RESET_PROB\n                new_weights = torch.randn_like(param.data)\n                param.data[mask] = new_weights[mask]\n        return model\n\n    # --- Helper: Tournament Selection ---\n    def tournament_selection(population, scores):\n        tournament_indices = torch.randint(0, len(population), (TOURNAMENT_SIZE,))\n        winner_idx = tournament_indices[torch.argmax(scores[tournament_indices])]\n        return population[winner_idx]\n\n    # --- Main Generation Logic ---\n    sorted_indices = torch.argsort(fitness_scores, descending=True)\n    num_elite = int(POPULATION_SIZE * ELITISM_RATE)\n    new_population = [current_population[i] for i in sorted_indices[:num_elite]]\n\n    num_children_to_create = POPULATION_SIZE - num_elite\n    for _ in range(num_children_to_create):\n        parent1 = tournament_selection(current_population, fitness_scores)\n        parent2 = tournament_selection(current_population, fitness_scores)\n        child = crossover(parent1, parent2, device)\n        child = mutate(child, device)\n        new_population.append(child)\n\n    return new_population\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 10.29%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 20.90%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 10.69%\n",
            "Finished evaluation. Operator 1 primary fitness: -11.3468\n",
            "\n",
            "--- Evaluating Operator Individual 2/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator: adaptive elitism, selection, mixed crossover, and adaptive mutation with immigrants.\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Ensure tensor scores on device ---\n    if not torch.is_tensor(fitness_scores):\n        scores = torch.tensor(fitness_scores, dtype=torch.float32, device=device)\n    else:\n        scores = fitness_scores.to(device=device, dtype=torch.float32)\n\n    # --- Fitness statistics for adaptive behavior ---\n    mean_abs = scores.abs().mean()\n    std = scores.std(unbiased=False)\n    coeff_var = float((std / (mean_abs + 1e-8)).item())\n\n    # --- Base hyperparameters ---\n    BASE_ELITISM = 0.10\n    BASE_TOURNAMENT_FRAC = 0.15\n    BASE_GAUSS_PROB = 0.02\n    BASE_GAUSS_SCALE = 0.10\n    BASE_RESET_PROB = 1e-4\n    BASE_LAYER_RESET_RATE = 0.01\n    BASE_LAYER_NOISE_RATE = 0.02\n    BASE_IMMIGRANT_RATE = 0.05\n    EXPLORE_PARENT_PROB = 0.15  # probability to pick random parent instead of tournament\n\n    # --- Adapt parameters based on stability (coeff_var) ---\n    if coeff_var < 0.05:\n        # Stagnation: increase exploration, more immigrants, stronger mutation\n        elitism_rate = max(0.03, BASE_ELITISM * 0.5)\n        tournament_frac = max(0.08, BASE_TOURNAMENT_FRAC * 0.7)\n        gauss_prob = min(0.08, BASE_GAUSS_PROB * 2.0)\n        gauss_scale = BASE_GAUSS_SCALE * 1.5\n        reset_prob = BASE_RESET_PROB * 3.0\n        layer_reset_rate = BASE_LAYER_RESET_RATE * 2.0\n        layer_noise_rate = BASE_LAYER_NOISE_RATE * 1.5\n        immigrant_rate = max(0.10, BASE_IMMIGRANT_RATE * 2.0)\n        explore_parent_prob = 0.30\n    elif coeff_var > 0.50:\n        # Unstable: more exploitation, tamer mutation, slightly stronger elitism\n        elitism_rate = min(0.18, BASE_ELITISM * 1.5)\n        tournament_frac = min(0.25, BASE_TOURNAMENT_FRAC * 1.3)\n        gauss_prob = max(0.005, BASE_GAUSS_PROB * 0.5)\n        gauss_scale = BASE_GAUSS_SCALE * 0.75\n        reset_prob = BASE_RESET_PROB * 0.5\n        layer_reset_rate = max(1e-4, BASE_LAYER_RESET_RATE * 0.5)\n        layer_noise_rate = max(0.005, BASE_LAYER_NOISE_RATE * 0.5)\n        immigrant_rate = max(0.02, BASE_IMMIGRANT_RATE * 0.5)\n        explore_parent_prob = 0.10\n    else:\n        # Stable improvement: gentle refinement\n        elitism_rate = BASE_ELITISM\n        tournament_frac = BASE_TOURNAMENT_FRAC\n        gauss_prob = BASE_GAUSS_PROB\n        gauss_scale = BASE_GAUSS_SCALE\n        reset_prob = BASE_RESET_PROB\n        layer_reset_rate = BASE_LAYER_RESET_RATE\n        layer_noise_rate = BASE_LAYER_NOISE_RATE\n        immigrant_rate = BASE_IMMIGRANT_RATE\n        explore_parent_prob = EXPLORE_PARENT_PROB\n\n    # Clamp values\n    tournament_size = max(3, min(POP_SIZE, int(round(POP_SIZE * tournament_frac))))\n    num_elite = max(1, int(POP_SIZE * elitism_rate))\n    num_immigrants = int(POP_SIZE * immigrant_rate)\n    num_immigrants = max(0, min(POP_SIZE - num_elite, num_immigrants))\n\n    # --- Helpers ---\n    def clone_model_from(src_model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(src_model.state_dict())\n        return m\n\n    def tournament_selection(population, scores_tensor):\n        if POP_SIZE == 1:\n            return population[0]\n        idxs = torch.randint(0, POP_SIZE, (tournament_size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_local = torch.argmax(sub_scores)\n        winner_idx = int(idxs[winner_local].item())\n        return population[winner_idx]\n\n    def select_parent(population, scores_tensor):\n        # Exploration: random parent with some probability\n        if torch.rand((), device=device).item() < explore_parent_prob:\n            ridx = int(torch.randint(0, POP_SIZE, (1,), device=device).item())\n            return population[ridx]\n        return tournament_selection(population, scores_tensor)\n\n    # Mixed crossover: uniform, blend, or tensor-swap chosen per tensor\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        cdict = child.state_dict()\n\n        for k in cdict.keys():\n            t1 = p1[k]\n            t2 = p2[k]\n            if not torch.is_floating_point(t1):\n                # For integer/bool buffers (e.g., num_batches_tracked), pick from a parent\n                if torch.rand((), device=device).item() < 0.5:\n                    cdict[k] = t1.clone()\n                else:\n                    cdict[k] = t2.clone()\n                continue\n\n            # Choose crossover mode for this tensor\n            r = torch.rand((), device=device).item()\n            if r < 0.5:\n                # Uniform crossover (per-element)\n                mask = torch.rand_like(t1) < 0.5\n                cdict[k] = torch.where(mask, t1, t2)\n            elif r < 0.9:\n                # Arithmetic blend crossover\n                alpha = torch.rand_like(t1)\n                cdict[k] = alpha * t1 + (1.0 - alpha) * t2\n            else:\n                # Whole-tensor parent swap\n                cdict[k] = t1.clone() if (torch.rand((), device=device).item() < 0.5) else t2.clone()\n\n        child.load_state_dict(cdict)\n        return child\n\n    # Adaptive mutation: gaussian noise, element resets, occasional layer resets/noise\n    fresh_template_state = SimpleNet().to(device).state_dict()\n\n    def mutate(model):\n        with torch.no_grad():\n            for (name, param) in model.named_parameters():\n                # Per-element gaussian noise\n                if gauss_prob > 0.0:\n                    mask_g = (torch.rand_like(param) < gauss_prob)\n                    # Scale by parameter std for scale-aware mutation\n                    p_std = param.detach().std()\n                    scale = gauss_scale * (p_std + 1e-8)\n                    noise = torch.randn_like(param) * scale\n                    param.add_(noise * mask_g)\n\n                # Per-element random reset to fresh initialization\n                if reset_prob > 0.0:\n                    mask_r = (torch.rand_like(param) < reset_prob)\n                    if mask_r.any():\n                        fresh_vals = fresh_template_state[name]\n                        param[mask_r] = fresh_vals[mask_r]\n\n                # Occasional layer-wise full reset\n                if torch.rand((), device=device).item() < layer_reset_rate:\n                    param.copy_(fresh_template_state[name])\n\n                # Occasional layer-wise gentle noise across entire tensor\n                if torch.rand((), device=device).item() < layer_noise_rate:\n                    p_std = param.detach().std()\n                    scale = (0.5 * gauss_scale) * (p_std + 1e-8)\n                    param.add_(torch.randn_like(param) * scale)\n        return model\n\n    # --- Build next population ---\n    new_population = []\n\n    # Sort individuals by fitness (descending)\n    sorted_indices = torch.argsort(scores, descending=True)\n\n    # Elitism: clone best individuals; gently jitter all but the top-1 elite to avoid premature convergence\n    elites = []\n    for rank in range(num_elite):\n        elite_model = clone_model_from(current_population[int(sorted_indices[rank].item())])\n        elites.append(elite_model)\n\n    # Jitter elites except best one (if more than 1 elite)\n    if len(elites) > 1:\n        with torch.no_grad():\n            for e in elites[1:]:\n                for p in e.parameters():\n                    p_std = p.detach().std()\n                    if torch.is_floating_point(p) and p_std > 0:\n                        e_scale = 0.02 * (p_std + 1e-8)\n                        p.add_(torch.randn_like(p) * e_scale)\n\n    new_population.extend(elites)\n\n    # Immigrants: inject fresh random individuals to preserve diversity\n    for _ in range(num_immigrants):\n        immigrant = SimpleNet().to(device)\n        new_population.append(immigrant)\n\n    # Children: fill the rest with selection + crossover + mutation\n    def distinct_parents():\n        p1 = select_parent(current_population, scores)\n        # Try to pick a different parent; fall back after a few tries\n        max_tries = 5\n        for _ in range(max_tries):\n            p2 = select_parent(current_population, scores)\n            if p2 is not p1:\n                return p1, p2\n        return p1, p2  # may be same if population small\n\n    while len(new_population) < POP_SIZE:\n        parent1, parent2 = distinct_parents()\n        child = crossover(parent1, parent2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # In case rounding led to overfill (shouldn't happen, but safe-guard)\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 15.80%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 9.57%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 10.36%\n",
            "Finished evaluation. Operator 2 primary fitness: -11.4440\n",
            "\n",
            "--- Evaluating Operator Individual 3/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    '''\n    Holistic evolutionary operator with adaptive selection pressure, crossover, and mutation.\n    - Rank-based selection with adaptive pressure.\n    - Mixed crossover: structured mask and arithmetic extrapolation (BLX-inspired).\n    - Adaptive mutation combining Gaussian noise, occasional resets, and tensor-level scaling.\n    - Elitism with safe cloning and optional gentle jitter when stagnating.\n    '''\n    POP_SIZE = len(current_population)\n    if POP_SIZE == 0:\n        return []\n\n    # --- Metrics for adaptive behavior ---\n    scores = fitness_scores.detach()\n    max_s = torch.max(scores)\n    min_s = torch.min(scores)\n    std_s = torch.std(scores)\n    rng = (max_s - min_s).abs().item() + 1e-12\n    spread_frac = (std_s.item() / rng)  # ~0..0.5 typical\n\n    stagnating = spread_frac < 0.15\n    unstable = spread_frac > 0.35\n\n    # --- Hyperparameters (adaptive) ---\n    if stagnating:\n        ELITISM_RATE = 0.10\n        SEL_PRESSURE = 2.0   # lower pressure -> more exploration\n        MUT_PROB = 0.008\n        GAUSS_SCALE = 0.20\n        RESET_PROB = 0.0010\n        GAMMA_EXTRAP = 0.35\n        TENSOR_SCALE_PROB = 0.030\n        ELITE_JITTER = True\n        ELITE_JITTER_NOISE = 0.02\n        ELITE_JITTER_MUT_PROB = 0.001\n    elif unstable:\n        ELITISM_RATE = 0.14\n        SEL_PRESSURE = 7.5   # higher pressure -> exploit\n        MUT_PROB = 0.003\n        GAUSS_SCALE = 0.08\n        RESET_PROB = 0.00010\n        GAMMA_EXTRAP = 0.12\n        TENSOR_SCALE_PROB = 0.010\n        ELITE_JITTER = False\n        ELITE_JITTER_NOISE = 0.0\n        ELITE_JITTER_MUT_PROB = 0.0\n    else:\n        ELITISM_RATE = 0.10\n        SEL_PRESSURE = 5.0\n        MUT_PROB = 0.004\n        GAUSS_SCALE = 0.12\n        RESET_PROB = 0.00030\n        GAMMA_EXTRAP = 0.18\n        TENSOR_SCALE_PROB = 0.015\n        ELITE_JITTER = False\n        ELITE_JITTER_NOISE = 0.0\n        ELITE_JITTER_MUT_PROB = 0.0\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE)) if POP_SIZE > 1 else 1\n\n    # --- Helper: clone model safely ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    # --- Rank-based selection probabilities with adaptive pressure ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    ranks = torch.empty_like(sorted_idx, dtype=torch.float, device=scores.device)\n    ranks[sorted_idx] = torch.arange(POP_SIZE, device=scores.device, dtype=torch.float)\n    denom = max(1, POP_SIZE - 1)\n    weights = torch.exp(-SEL_PRESSURE * (ranks / denom))\n    probs = weights / (weights.sum() + 1e-12)\n\n    def select_parent_index():\n        return int(torch.multinomial(probs, num_samples=1, replacement=True).item())\n\n    # --- Crossover operator (structured mask + arithmetic extrapolation) ---\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        cdict = child.state_dict()\n        with torch.no_grad():\n            for k in cdict.keys():\n                t1 = p1[k].to(device)\n                t2 = p2[k].to(device)\n                # Randomly choose crossover mode per tensor\n                # 50% structured mask, 50% arithmetic extrapolation\n                if torch.rand(()) < 0.5:\n                    # Structured mask: broadcast mask across last dim for stability when tensor is matrix-like\n                    if t1.dim() >= 2:\n                        mask_shape = list(t1.shape)\n                        mask_shape[-1] = 1\n                        mask = (torch.rand(mask_shape, device=device) < 0.5).expand_as(t1)\n                    else:\n                        mask = (torch.rand_like(t1) < 0.5)\n                    cdict[k] = torch.where(mask, t1, t2)\n                else:\n                    # Arithmetic extrapolation: beta in [-gamma, 1+gamma]\n                    beta = torch.empty_like(t1).uniform_(-GAMMA_EXTRAP, 1.0 + GAMMA_EXTRAP)\n                    cdict[k] = beta * t1 + (1.0 - beta) * t2\n        child.load_state_dict(cdict)\n        return child\n\n    # --- Mutation operator (adaptive gaussian + reset + tensor scaling) ---\n    def mutate(model, mut_prob=MUT_PROB, gauss_scale=GAUSS_SCALE, reset_prob=RESET_PROB, tensor_scale_prob=TENSOR_SCALE_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if p.requires_grad:\n                    # Gaussian mutation on a subset of weights\n                    mask = torch.rand_like(p) < mut_prob\n                    # Derive local std for scale-aware noise; fallback to 1.0 if near-constant\n                    local_std = p.detach().std()\n                    if not torch.isfinite(local_std) or local_std.item() < 1e-8:\n                        local_std = torch.tensor(1.0, device=p.device)\n                    noise = torch.randn_like(p) * (gauss_scale * local_std)\n                    p[mask] = p[mask] + noise[mask]\n\n                    # Occasional reset mutation\n                    reset_mask = torch.rand_like(p) < reset_prob\n                    if reset_mask.any():\n                        p[reset_mask] = torch.randn_like(p[reset_mask]) * (0.5 * local_std + 1e-8)\n\n                    # Tensor-level scaling mutation (structural)\n                    if torch.rand(()) < tensor_scale_prob:\n                        scale = 1.0 + (0.10 * torch.randn((), device=p.device))\n                        p.mul_(scale)\n\n        return model\n\n    # --- Build next population ---\n    new_population = []\n\n    # Elitism: clone top individuals\n    elites_idx = sorted_idx[:num_elite]\n    for j, idx in enumerate(elites_idx):\n        elite_clone = clone_model(current_population[int(idx)])\n        # Optional gentle jitter for exploration when stagnating (except absolute best)\n        if ELITE_JITTER and j > 0 and POP_SIZE > 2:\n            mutate(elite_clone, mut_prob=ELITE_JITTER_MUT_PROB, gauss_scale=ELITE_JITTER_NOISE, reset_prob=0.0, tensor_scale_prob=0.0)\n        new_population.append(elite_clone)\n\n    # Generate offspring\n    offspring_needed = POP_SIZE - len(new_population)\n    for _ in range(offspring_needed):\n        # Select parents (avoid identical parents when possible)\n        p1_idx = select_parent_index()\n        p2_idx = select_parent_index()\n        tries = 0\n        while p2_idx == p1_idx and tries < 3 and POP_SIZE > 1:\n            p2_idx = select_parent_index()\n            tries += 1\n\n        parent1 = current_population[p1_idx]\n        parent2 = current_population[p2_idx if POP_SIZE > 1 else p1_idx]\n\n        child = crossover(parent1, parent2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if population size drifted, trim or pad with clones\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # pad with clones of best\n        best_model = current_population[int(sorted_idx[0])]\n        while len(new_population) < POP_SIZE:\n            new_population.append(clone_model(best_model))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 12.09%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 13.81%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 17.94%\n",
            "Finished evaluation. Operator 3 primary fitness: -11.4160\n",
            "\n",
            "--- Evaluating Operator Individual 4/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\n```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Evolves the population using a strategy that balances exploration and exploitation.\n\n    This operator employs:\n    - Elitism: Preserves the best-performing individuals.\n    - Tournament Selection: Selects parents with a pressure towards higher fitness.\n    - Fitness-Weighted Crossover: Creates offspring by blending parent weights,\n      giving more influence to the fitter parent.\n    - Gaussian Mutation: Applies small, random perturbations to weights, allowing\n      for fine-tuning and exploration of the local search space.\n    \"\"\"\n    POPULATION_SIZE = len(current_population)\n    \n    # --- Hyperparameters ---\n    ELITISM_RATE = 0.10          # Preserve the top 10% of the population\n    TOURNAMENT_SIZE = 5          # Size of the selection tournament\n    MUTATION_RATE = 0.05         # Probability of a single weight being mutated\n    MUTATION_STRENGTH = 0.1      # Standard deviation of the Gaussian noise for mutation\n\n    # --- Helper: Fitness-Weighted Crossover ---\n    def fitness_weighted_crossover(parent1, parent2, fitness1, fitness2, device):\n        \"\"\"\n        Creates a child by performing a weighted average of the parents' weights.\n        The weights are proportional to the parents' fitness scores.\n        \"\"\"\n        child = SimpleNet().to(device)\n        p1_dict = parent1.state_dict()\n        p2_dict = parent2.state_dict()\n        child_dict = child.state_dict()\n\n        # Handle potential for zero or negative fitness\n        total_fitness = fitness1 + fitness2\n        if total_fitness <= 1e-6: # Avoid division by zero or negative weights\n            w1, w2 = 0.5, 0.5\n        else:\n            w1 = fitness1 / total_fitness\n            w2 = fitness2 / total_fitness\n\n        with torch.no_grad():\n            for key in p1_dict.keys():\n                child_dict[key] = w1 * p1_dict[key] + w2 * p2_dict[key]\n        \n        child.load_state_dict(child_dict)\n        return child\n\n    # --- Helper: Gaussian Mutation ---\n    def gaussian_mutate(model, device):\n        \"\"\"\n        Applies additive Gaussian noise to a subset of the model's weights.\n        \"\"\"\n        with torch.no_grad():\n            for param in model.parameters():\n                if len(param.shape) > 1: # Apply only to weight matrices/conv kernels\n                    mask = torch.rand_like(param.data) < MUTATION_RATE\n                    noise = torch.randn_like(param.data) * MUTATION_STRENGTH\n                    param.data += noise * mask\n        return model\n\n    # --- Helper: Tournament Selection ---\n    def tournament_selection(population, scores):\n        \"\"\"\n        Selects an individual from the population using a tournament.\n        Returns the winner and its index.\n        \"\"\"\n        # Pick TOURNAMENT_SIZE random indices\n        tournament_indices = torch.randint(0, len(population), (TOURNAMENT_SIZE,))\n        \n        # Find the index of the best individual within the tournament\n        winner_local_idx = torch.argmax(scores[tournament_indices])\n        winner_global_idx = tournament_indices[winner_local_idx]\n        \n        return population[winner_global_idx], winner_global_idx\n\n    # --- Main Generation Logic ---\n    \n    # 1. Elitism: Carry over the best individuals to the next generation\n    sorted_indices = torch.argsort(fitness_scores, descending=True)\n    num_elite = int(POPULATION_SIZE * ELITISM_RATE)\n    new_population = [current_population[i] for i in sorted_indices[:num_elite]]\n\n    # 2. Crossover and Mutation: Create the rest of the new population\n    num_children_to_create = POPULATION_SIZE - num_elite\n    for _ in range(num_children_to_create):\n        # Select two distinct parents\n        parent1, p1_idx = tournament_selection(current_population, fitness_scores)\n        parent2, p2_idx = tournament_selection(current_population, fitness_scores)\n        while p1_idx == p2_idx:\n            parent2, p2_idx = tournament_selection(current_population, fitness_scores)\n            \n        p1_fitness = fitness_scores[p1_idx]\n        p2_fitness = fitness_scores[p2_idx]\n\n        # Create child through crossover\n        child = fitness_weighted_crossover(parent1, parent2, p1_fitness, p2_fitness, device)\n        \n        # Mutate the child\n        child = gaussian_mutate(child, device)\n        \n        new_population.append(child)\n\n    return new_population\n```\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error executing evolved code. Attempting LLM repair (1/1).\n",
            "--- Calling Google API to repair operator ---\n",
            "Error executing evolved code after repair attempts: invalid syntax (<string>, line 1)\n",
            "Finished evaluation. Operator 4 failed and was assigned a fitness of -inf.\n",
            "\n",
            "--- Evaluating Operator Individual 5/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with adaptive diversity control.\n    - Elitism with cloning\n    - Adaptive tournament size\n    - Dynamic crossover strategy (Uniform / BLX-alpha)\n    - Adaptive Gaussian and reset mutation\n    - Immigrants injection when diversity is low\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Guard for degenerate populations\n    if POP_SIZE == 0:\n        return []\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    low_diversity = cv.item() < 0.05\n    unstable = cv.item() > 0.5\n\n    # --- Adaptive hyperparameters ---\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        TOURNAMENT_SIZE = 3\n        GAUSS_MUT_PROB = 0.02\n        GAUSS_SIGMA = 0.10\n        RESET_MUT_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.05\n        CROSSOVER_MODE = \"blx\"  # BLX-alpha crossover to expand search\n        BLX_ALPHA = 0.20\n    elif unstable:\n        ELITISM_RATE = 0.07\n        TOURNAMENT_SIZE = 7\n        GAUSS_MUT_PROB = 0.006\n        GAUSS_SIGMA = 0.03\n        RESET_MUT_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.01\n        CROSSOVER_MODE = \"uniform\"  # stabilize around good schemas\n        BLX_ALPHA = 0.10\n    else:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 5\n        GAUSS_MUT_PROB = 0.01\n        GAUSS_SIGMA = 0.05\n        RESET_MUT_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.02\n        CROSSOVER_MODE = \"mixed\"  # combine uniform and arithmetic\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        c = child.state_dict()\n\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = p1[k]\n                t2 = p2[k]\n                if CROSSOVER_MODE == \"uniform\":\n                    mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                    c[k] = t1 * mask + t2 * (1.0 - mask)\n                elif CROSSOVER_MODE == \"blx\":\n                    c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                else:  # mixed\n                    # 50% uniform mask, 50% arithmetic blend with per-element alpha in [0.25, 0.75]\n                    if torch.rand((), device=device) < 0.5:\n                        mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                        c[k] = t1 * mask + t2 * (1.0 - mask)\n                    else:\n                        alpha = 0.25 + 0.5 * torch.rand_like(t1)\n                        c[k] = alpha * t1 + (1.0 - alpha) * t2\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, gauss_prob=GAUSS_MUT_PROB, gauss_sigma=GAUSS_SIGMA, reset_prob=RESET_MUT_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if gauss_prob > 0.0:\n                    gmask = torch.rand_like(p) < gauss_prob\n                    noise = torch.randn_like(p) * gauss_sigma\n                    p[gmask] = p[gmask] + noise[gmask]\n                if reset_prob > 0.0:\n                    rmask = torch.rand_like(p) < reset_prob\n                    new_vals = torch.randn_like(p)\n                    p[rmask] = new_vals[rmask]\n        return model\n\n    def tournament_selection(population, scores_tensor, size=TOURNAMENT_SIZE):\n        idxs = torch.randint(0, len(population), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = int(idxs[torch.argmax(sub_scores)].item())\n        return population[winner_idx]\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = []\n    for i in range(num_elite):\n        elites.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    new_population = list(elites)\n\n    # Immigrants (fresh random individuals) for diversity\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        p1 = tournament_selection(current_population, scores)\n        # ensure different parents where possible\n        p2 = p1\n        attempts = 0\n        while p2 is p1 and attempts < 3:\n            p2 = tournament_selection(current_population, scores)\n            attempts += 1\n\n        child = crossover(p1, p2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if rounding errors occur, adjust size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # Fill up with additional mutated clones of elites\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            extra = clone_model(current_population[int(sorted_idx[i % len(sorted_idx)].item())])\n            new_population.append(mutate(extra))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 10.52%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 16.90%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 15.96%\n",
            "Finished evaluation. Operator 5 primary fitness: -11.3403\n",
            "\n",
            "--- Evaluating Operator Individual 6/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with adaptive exploration-exploitation balance.\n    - Elitism (deep copies)\n    - Adaptive tournament selection\n    - Mixed crossover (uniform/arithmetic/whole-tensor)\n    - Adaptive mutation (Gaussian + reset) with immigrant injection under low diversity/spread\n    \"\"\"\n    POP_SIZE = len(current_population)\n    if POP_SIZE == 0:\n        return []\n\n    # ----------------- Helpers -----------------\n    def clone_model(src_model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(src_model.state_dict())\n        return m\n\n    def flatten_vector(model, max_elems=50000):\n        with torch.no_grad():\n            vecs = []\n            count = 0\n            for p in model.parameters():\n                t = p.detach().float().view(-1).cpu()\n                if count + t.numel() <= max_elems:\n                    vecs.append(t)\n                    count += t.numel()\n                else:\n                    remaining = max(0, max_elems - count)\n                    if remaining > 0:\n                        vecs.append(t[:remaining])\n                        count += remaining\n                    break\n            if len(vecs) == 0:\n                return torch.zeros(1)\n            return torch.cat(vecs)\n\n    def estimate_diversity_and_spread(population, scores):\n        # Diversity from top-K models using cosine similarity of flattened weights\n        K = min(6, len(population))\n        if K < 2:\n            diversity = 0.0\n        else:\n            top_idx = torch.argsort(scores, descending=True)[:K]\n            mats = []\n            for idx in top_idx:\n                v = flatten_vector(population[int(idx)])\n                if v.norm() == 0:\n                    v = v + 1e-6\n                mats.append(v / (v.norm() + 1e-8))\n            V = torch.stack(mats)  # K x D\n            cos = (V @ V.t())\n            # exclude diagonal\n            avg_offdiag = (cos.sum() - torch.trace(cos)) / (K * (K - 1))\n            avg_offdiag = torch.clamp(avg_offdiag, -1.0, 1.0)\n            diversity = float(1.0 - avg_offdiag)\n        # Spread of fitness\n        s = scores.float()\n        mean_abs = torch.mean(torch.abs(s)) + 1e-6\n        std = torch.std(s)\n        spread_ratio = float(std / mean_abs)\n        return diversity, spread_ratio\n\n    def dynamic_params(diversity, spread_ratio):\n        # Targets\n        target_diversity = 0.18\n        target_spread = 0.08\n\n        lack_div = max(0.0, (target_diversity - diversity) / max(1e-6, target_diversity))\n        lack_spread = max(0.0, (target_spread - spread_ratio) / max(1e-6, target_spread))\n\n        exploration_pressure = min(2.0, 0.5 * lack_spread + 0.5 * lack_div)  # [0, 2]\n        # Mutation scaling factor\n        mut_scale = 1.0 + 1.5 * exploration_pressure  # [1, 4]\n        # Immigrant rate\n        imm_rate = min(0.25, 0.04 * (1.0 + 2.0 * exploration_pressure))  # up to 25%\n        # Tournament size (smaller -> more exploration when exploration_pressure high)\n        t_min, t_max = 3, max(4, min(9, POP_SIZE // 4 + 3))\n        tsize = int(round(t_max - (t_max - t_min) * min(1.0, 0.5 + 0.5 * diversity)))\n        tsize = max(3, min(t_max, tsize))\n        # Crossover probability adapts inversely to exploration (slightly)\n        cx_prob = max(0.65, 0.9 - 0.15 * exploration_pressure)\n\n        return mut_scale, imm_rate, tsize, cx_prob\n\n    def tournament_selection(population, scores, tsize):\n        idxs = torch.randint(low=0, high=len(population), size=(tsize,))\n        best_local = idxs[torch.argmax(scores[idxs])]\n        return population[int(best_local)]\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        cdict = child.state_dict()\n        with torch.no_grad():\n            for k in cdict.keys():\n                a = p1[k]\n                b = p2[k]\n                # Non-floating tensors (e.g., BatchNorm counters): take from one parent\n                if not torch.is_floating_point(cdict[k]):\n                    pick_first = bool(torch.randint(0, 2, (1,), device=device).item())\n                    cdict[k] = a.clone() if pick_first else b.clone()\n                    continue\n\n                shape = a.shape\n                r = torch.rand((), device=device)\n                if r < 0.10:\n                    # Whole-tensor pick\n                    pick_first = bool(torch.randint(0, 2, (1,), device=device).item())\n                    cdict[k] = a.clone() if pick_first else b.clone()\n                elif r < 0.50:\n                    # Element-wise uniform mask\n                    mask = (torch.rand(shape, device=device) < 0.5).to(a.dtype)\n                    cdict[k] = a * mask + b * (1.0 - mask)\n                else:\n                    # Arithmetic blend with random alpha per-tensor\n                    alpha = torch.rand((), device=device)\n                    cdict[k] = alpha * a + (1.0 - alpha) * b\n\n                # Light crossover noise\n                if torch.is_floating_point(cdict[k]):\n                    # Scale noise by parameter scale\n                    scale = torch.std(cdict[k].float())\n                    noise = torch.randn_like(cdict[k]) * (0.01 * (float(scale) + 1e-6))\n                    cdict[k].add_(noise)\n        child.load_state_dict(cdict)\n        return child\n\n    def mutate(model, mut_scale=1.0):\n        base_point_rate = 0.02\n        base_sigma = 0.02\n        base_reset_rate = 0.0005\n        tensor_noise_prob = 0.02\n\n        point_rate = min(0.5, base_point_rate * mut_scale)\n        sigma = base_sigma * mut_scale\n        reset_rate = min(0.1, base_reset_rate * mut_scale)\n\n        with torch.no_grad():\n            for p in model.parameters():\n                if not torch.is_floating_point(p):\n                    continue\n                # Element-wise perturbation\n                mask = torch.rand_like(p) < point_rate\n                if mask.any():\n                    scale = torch.std(p.float()) + 1e-6\n                    noise = torch.randn_like(p) * (sigma * float(scale))\n                    p[mask] = p[mask] + noise[mask]\n\n                # Occasional whole-tensor small noise\n                if torch.rand((), device=device) < tensor_noise_prob * min(2.0, mut_scale):\n                    scale = torch.std(p.float()) + 1e-6\n                    p.add_(torch.randn_like(p) * (0.5 * sigma * float(scale)))\n\n                # Reset mutation\n                rmask = torch.rand_like(p) < reset_rate\n                if rmask.any():\n                    scale = torch.std(p.float()) + 1e-6\n                    new_weights = torch.randn_like(p) * float(scale)\n                    p[rmask] = new_weights[rmask]\n        return model\n\n    # ----------------- Main -----------------\n    scores = fitness_scores.detach().float()\n    diversity, spread_ratio = estimate_diversity_and_spread(current_population, scores)\n    mut_scale, imm_rate, TOURNAMENT_SIZE, CX_PROB = dynamic_params(diversity, spread_ratio)\n\n    # Elitism\n    ELITISM_RATE = 0.08\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = [clone_model(current_population[int(i)]) for i in sorted_idx[:num_elite]]\n\n    # Slightly perturb a subset of elites for soft exploration\n    if num_elite > 1:\n        elite_mutate_count = max(1, num_elite // 2)\n        for i in range(elite_mutate_count):\n            elites[i] = mutate(elites[i], mut_scale=0.5)\n\n    new_population = []\n    new_population.extend(elites)\n\n    # Immigrants (random new individuals)\n    num_immigrants = min(POP_SIZE - len(new_population), int(POP_SIZE * imm_rate))\n    for _ in range(num_immigrants):\n        m = SimpleNet().to(device)\n        # Give immigrants a stronger initial mutation to diversify\n        m = mutate(m, mut_scale=1.5 * mut_scale)\n        new_population.append(m)\n\n    # Fill the rest via selection, crossover, mutation\n    while len(new_population) < POP_SIZE:\n        parent1 = tournament_selection(current_population, scores, TOURNAMENT_SIZE)\n        # Select second parent; encourage diversity by sampling a few and picking the most different\n        candidates = [tournament_selection(current_population, scores, TOURNAMENT_SIZE) for _ in range(3)]\n        # Choose most different from parent1 among candidates by comparing a small random projection\n        p1_vec = None\n        best_cand = candidates[0]\n        best_score = -1.0\n        for cand in candidates:\n            # quick proxy: compare norms difference of a single parameter tensor\n            with torch.no_grad():\n                p1p = next(parent1.parameters()).detach().float().view(-1)\n                p2p = next(cand.parameters()).detach().float().view(-1)\n                ln = min(p1p.numel(), p2p.numel(), 1024)\n                d = torch.norm(p1p[:ln] - p2p[:ln]) / (torch.norm(p1p[:ln]) + 1e-6)\n                val = float(d)\n                if val > best_score:\n                    best_score = val\n                    best_cand = cand\n        parent2 = best_cand\n\n        do_crossover = torch.rand((), device=device) < CX_PROB\n        if bool(do_crossover.item()):\n            child = crossover(parent1, parent2)\n        else:\n            child = clone_model(parent1)\n        child = mutate(child, mut_scale=mut_scale)\n        new_population.append(child)\n\n    # Ensure exact population size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 9.62%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 15.64%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 17.98%\n",
            "Finished evaluation. Operator 6 primary fitness: -11.4327\n",
            "\n",
            "--- Meta-Generation 1 Results ---\n",
            "Best Operator Fitness (Avg Final Best): -11.3403\n",
            "Best Performing Operator's Code:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with adaptive diversity control.\n    - Elitism with cloning\n    - Adaptive tournament size\n    - Dynamic crossover strategy (Uniform / BLX-alpha)\n    - Adaptive Gaussian and reset mutation\n    - Immigrants injection when diversity is low\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Guard for degenerate populations\n    if POP_SIZE == 0:\n        return []\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    low_diversity = cv.item() < 0.05\n    unstable = cv.item() > 0.5\n\n    # --- Adaptive hyperparameters ---\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        TOURNAMENT_SIZE = 3\n        GAUSS_MUT_PROB = 0.02\n        GAUSS_SIGMA = 0.10\n        RESET_MUT_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.05\n        CROSSOVER_MODE = \"blx\"  # BLX-alpha crossover to expand search\n        BLX_ALPHA = 0.20\n    elif unstable:\n        ELITISM_RATE = 0.07\n        TOURNAMENT_SIZE = 7\n        GAUSS_MUT_PROB = 0.006\n        GAUSS_SIGMA = 0.03\n        RESET_MUT_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.01\n        CROSSOVER_MODE = \"uniform\"  # stabilize around good schemas\n        BLX_ALPHA = 0.10\n    else:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 5\n        GAUSS_MUT_PROB = 0.01\n        GAUSS_SIGMA = 0.05\n        RESET_MUT_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.02\n        CROSSOVER_MODE = \"mixed\"  # combine uniform and arithmetic\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        c = child.state_dict()\n\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = p1[k]\n                t2 = p2[k]\n                if CROSSOVER_MODE == \"uniform\":\n                    mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                    c[k] = t1 * mask + t2 * (1.0 - mask)\n                elif CROSSOVER_MODE == \"blx\":\n                    c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                else:  # mixed\n                    # 50% uniform mask, 50% arithmetic blend with per-element alpha in [0.25, 0.75]\n                    if torch.rand((), device=device) < 0.5:\n                        mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                        c[k] = t1 * mask + t2 * (1.0 - mask)\n                    else:\n                        alpha = 0.25 + 0.5 * torch.rand_like(t1)\n                        c[k] = alpha * t1 + (1.0 - alpha) * t2\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, gauss_prob=GAUSS_MUT_PROB, gauss_sigma=GAUSS_SIGMA, reset_prob=RESET_MUT_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if gauss_prob > 0.0:\n                    gmask = torch.rand_like(p) < gauss_prob\n                    noise = torch.randn_like(p) * gauss_sigma\n                    p[gmask] = p[gmask] + noise[gmask]\n                if reset_prob > 0.0:\n                    rmask = torch.rand_like(p) < reset_prob\n                    new_vals = torch.randn_like(p)\n                    p[rmask] = new_vals[rmask]\n        return model\n\n    def tournament_selection(population, scores_tensor, size=TOURNAMENT_SIZE):\n        idxs = torch.randint(0, len(population), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = int(idxs[torch.argmax(sub_scores)].item())\n        return population[winner_idx]\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = []\n    for i in range(num_elite):\n        elites.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    new_population = list(elites)\n\n    # Immigrants (fresh random individuals) for diversity\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        p1 = tournament_selection(current_population, scores)\n        # ensure different parents where possible\n        p2 = p1\n        attempts = 0\n        while p2 is p1 and attempts < 3:\n            p2 = tournament_selection(current_population, scores)\n            attempts += 1\n\n        child = crossover(p1, p2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if rounding errors occur, adjust size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # Fill up with additional mutated clones of elites\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            extra = clone_model(current_population[int(sorted_idx[i % len(sorted_idx)].item())])\n            new_population.append(mutate(extra))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Operator's Performance Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This operator's performance has been recorded over **3** separate runs.\nThe table below shows the fitness dynamics, **averaged across all runs**.\nFitness is based on the negative loss on training batches (higher is better).\n\n| Gen | Best Fitness | Avg Fitness  | Worst Fitness | Spread (Diversity) |\n|:---:|:------------:|:------------:|:-------------:|:------------------:|\n|  0  |     -11.4630 |     -11.5397 |      -11.6121 |             0.1491 |\n|  1  |     -11.4313 |     -11.5767 |      -12.1839 |             0.7526 |\n|  2  |     -11.4298 |     -11.5916 |      -11.9507 |             0.5209 |\n|  3  |     -11.3812 |     -11.6047 |      -11.9569 |             0.5757 |\n|  4  |     -11.3890 |     -11.6302 |      -12.2664 |             0.8774 |\n|  5  |     -11.3751 |     -11.6719 |      -13.6228 |             2.2477 |\n|  6  |     -11.3837 |     -11.6159 |      -12.1176 |             0.7339 |\n|  7  |     -11.3677 |     -11.6666 |      -12.3902 |             1.0226 |\n|  8  |     -11.3426 |     -11.6645 |      -12.4404 |             1.0978 |\n|  9  |     -11.3403 |     -11.6956 |      -13.2220 |             1.8817 |\n\n**Analysis Hints for Your Evolution:**\n- **Rate of Improvement:** Analyze the slope of the `Best Fitness` column. A steep, consistent increase is ideal.\n- **Population Diversity:** The `Spread (Best-Worst)` column is a proxy for diversity. If it collapses to near-zero too quickly, the population has prematurely converged, and you should consider changes that increase exploration (e.g., higher mutation, different selection).\n- **Stability:** Smooth, predictable improvements indicate a stable operator. Jagged or erratic values might suggest the operator is too chaotic."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Calling Google API to evolve operator (with generational feedback) ---\n",
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "\n",
            "========================= META-GENERATION 2/4 =========================\n",
            "Evolving the `generate_next_population` operator...\n",
            "\n",
            "--- Evaluating Operator Individual 2/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\n```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator evolved for stable improvement.\n    - Increased elitism to preserve high-performing individuals.\n    - Adaptive tournament size with slightly reduced pressure in unstable states.\n    - Refined crossover: standard arithmetic blend for exploitation, BLX for exploration.\n    - Tuned mutation: reduced destructive reset mutations to improve average fitness.\n    - Strategic immigrant injection, paused during unstable phases to aid convergence.\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Guard for degenerate populations\n    if POP_SIZE == 0:\n        return []\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    low_diversity = cv.item() < 0.05\n    unstable = cv.item() > 0.4 # Slightly more sensitive to instability\n\n    # --- Adaptive hyperparameters (Evolved) ---\n    if low_diversity:\n        # Increase exploration and diversity\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 3\n        GAUSS_MUT_PROB = 0.02\n        GAUSS_SIGMA = 0.10\n        RESET_MUT_PROB = 2e-4  # Reduced destructive mutation\n        IMMIGRANTS_RATE = 0.05\n        CROSSOVER_MODE = \"blx\"\n        BLX_ALPHA = 0.15       # Reduced BLX range\n    elif unstable:\n        # Stabilize population, increase exploitation\n        ELITISM_RATE = 0.12      # Higher elitism to lock in gains\n        TOURNAMENT_SIZE = 6      # Reduced pressure\n        GAUSS_MUT_PROB = 0.005\n        GAUSS_SIGMA = 0.03\n        RESET_MUT_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.00   # No random immigrants when unstable\n        CROSSOVER_MODE = \"uniform\"\n    else: # Balanced state\n        ELITISM_RATE = 0.12\n        TOURNAMENT_SIZE = 5\n        GAUSS_MUT_PROB = 0.015   # Increased local search\n        GAUSS_SIGMA = 0.05\n        RESET_MUT_PROB = 5e-5    # Reduced destructive mutation\n        IMMIGRANTS_RATE = 0.02\n        CROSSOVER_MODE = \"arithmetic_blend\"\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1_sd = parent1.state_dict()\n        p2_sd = parent2.state_dict()\n        child_sd = child.state_dict()\n\n        with torch.no_grad():\n            for k in child_sd.keys():\n                t1 = p1_sd[k]\n                t2 = p2_sd[k]\n                if CROSSOVER_MODE == \"uniform\":\n                    mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                    child_sd[k] = t1 * mask + t2 * (1.0 - mask)\n                elif CROSSOVER_MODE == \"blx\":\n                    child_sd[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                else:  # arithmetic_blend\n                    alpha = torch.rand((), device=device) # Uniform random blend factor\n                    child_sd[k] = alpha * t1 + (1.0 - alpha) * t2\n        child.load_state_dict(child_sd)\n        return child\n\n    def mutate(model, gauss_prob=GAUSS_MUT_PROB, gauss_sigma=GAUSS_SIGMA, reset_prob=RESET_MUT_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if gauss_prob > 0.0:\n                    gmask = torch.rand_like(p) < gauss_prob\n                    noise = torch.randn_like(p) * gauss_sigma\n                    p.add_(noise * gmask)\n                if reset_prob > 0.0:\n                    rmask = torch.rand_like(p) < reset_prob\n                    p[rmask] = torch.randn_like(p[rmask])\n        return model\n\n    def tournament_selection(population, scores_tensor, size=TOURNAMENT_SIZE):\n        idxs = torch.randint(0, len(population), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = idxs[torch.argmax(sub_scores)].item()\n        return population[winner_idx]\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = [clone_model(current_population[i.item()]) for i in sorted_idx[:num_elite]]\n\n    new_population = list(elites)\n\n    # Immigrants (fresh random individuals) for diversity\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        parent1 = tournament_selection(current_population, scores)\n        parent2 = parent1\n        attempts = 0\n        while parent2 is parent1 and attempts < 5:\n            parent2 = tournament_selection(current_population, scores)\n            attempts += 1\n\n        child = crossover(parent1, parent2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if rounding errors occur, adjust size to match POP_SIZE\n    while len(new_population) < POP_SIZE:\n        # Fill shortage with mutated clones of the best individuals\n        filler_parent = elites[len(new_population) % len(elites)]\n        new_individual = mutate(clone_model(filler_parent))\n        new_population.append(new_individual)\n\n    return new_population[:POP_SIZE]\n```\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error executing evolved code. Attempting LLM repair (1/1).\n",
            "--- Calling Google API to repair operator ---\n",
            "Error executing evolved code after repair attempts: invalid syntax (<string>, line 1)\n",
            "Finished evaluation. Operator 2 failed and was assigned a fitness of -inf.\n",
            "\n",
            "--- Evaluating Operator Individual 3/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with rank-based selection, bias-preserving crossover,\n    and fitness-adaptive mutation to increase exploitation stability without collapsing diversity.\n    \"\"\"\n    POP_SIZE = len(current_population)\n    if POP_SIZE == 0:\n        return []\n    if POP_SIZE == 1:\n        # Keep population size; apply light mutation to explore a bit\n        lone = SimpleNet().to(device)\n        lone.load_state_dict(current_population[0].state_dict())\n        with torch.no_grad():\n            for p in lone.parameters():\n                std = torch.std(p)\n                scale = (std if torch.isfinite(std) and std > 0 else torch.tensor(1.0, device=device))\n                mask = torch.rand_like(p) < 0.01\n                p[mask] = p[mask] + torch.randn_like(p[mask]) * 0.03 * scale\n        return [lone]\n\n    # Prepare fitness tensor\n    if not torch.is_tensor(fitness_scores):\n        scores = torch.tensor(fitness_scores, dtype=torch.float32, device=device)\n    else:\n        scores = fitness_scores.to(device=device, dtype=torch.float32)\n\n    # Diversity diagnostics\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n    cv_val = float(cv.item())\n\n    low_diversity = cv_val < 0.08\n    high_diversity = cv_val > 0.30\n\n    # Adaptive hyperparameters (tuned for more stable improvement)\n    if high_diversity:\n        ELITISM_RATE = 0.18\n        GAUSS_MUT_PROB = 0.004\n        GAUSS_SIGMA = 0.02\n        RESET_MUT_PROB = 0.0\n        IMMIGRANTS_RATE = 0.0\n        CROSSOVER_MODE = \"biased\"\n        CROSSOVER_RATE = 0.90\n        SELECTION_Q = 0.22  # stronger pressure toward top\n        BLX_ALPHA = 0.10\n        BASE_BIAS = 0.64\n    elif low_diversity:\n        ELITISM_RATE = 0.08\n        GAUSS_MUT_PROB = 0.015\n        GAUSS_SIGMA = 0.08\n        RESET_MUT_PROB = 3e-4\n        IMMIGRANTS_RATE = 0.04\n        CROSSOVER_MODE = \"explore\"\n        CROSSOVER_RATE = 0.98\n        SELECTION_Q = 0.35  # flatter selection to widen search\n        BLX_ALPHA = 0.25\n        BASE_BIAS = 0.56\n    else:\n        ELITISM_RATE = 0.14\n        GAUSS_MUT_PROB = 0.007\n        GAUSS_SIGMA = 0.035\n        RESET_MUT_PROB = 5e-5\n        IMMIGRANTS_RATE = 0.01\n        CROSSOVER_MODE = \"mixed\"\n        CROSSOVER_RATE = 0.93\n        SELECTION_Q = 0.28\n        BLX_ALPHA = 0.15\n        BASE_BIAS = 0.60\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # Utilities\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def biased_arithmetic_mix(t1, t2, better_first=True, base_bias=0.6, jitter=0.1):\n        # Per-element alpha around base_bias with small jitter\n        alpha = base_bias + (torch.rand_like(t1) - 0.5) * 2.0 * jitter\n        alpha = torch.clamp(alpha, 0.4, 0.9)\n        if better_first:\n            return alpha * t1 + (1.0 - alpha) * t2\n        else:\n            return alpha * t2 + (1.0 - alpha) * t1\n\n    def crossover(parent1, parent2, s1, s2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        c = child.state_dict()\n        better_is_p1 = bool(s1 >= s2)\n\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = p1[k]\n                t2 = p2[k]\n                if torch.rand((), device=device) > CROSSOVER_RATE:\n                    # No crossover: take better parent weights directly\n                    c[k] = t1.clone() if better_is_p1 else t2.clone()\n                    continue\n\n                if CROSSOVER_MODE == \"biased\":\n                    # Bias towards better parent with mild jitter\n                    c[k] = biased_arithmetic_mix(t1, t2, better_first=better_is_p1, base_bias=BASE_BIAS, jitter=0.08)\n                elif CROSSOVER_MODE == \"explore\":\n                    # Mostly BLX for exploration, sometimes biased arithmetic\n                    if torch.rand((), device=device) < 0.7:\n                        c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                    else:\n                        c[k] = biased_arithmetic_mix(t1, t2, better_first=better_is_p1, base_bias=0.55, jitter=0.15)\n                else:  # \"mixed\"\n                    # Blend: 60% biased arithmetic, 40% BLX\n                    if torch.rand((), device=device) < 0.6:\n                        c[k] = biased_arithmetic_mix(t1, t2, better_first=better_is_p1, base_bias=BASE_BIAS, jitter=0.10)\n                    else:\n                        c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, gauss_prob, gauss_sigma, reset_prob, intensity=1.0):\n        # Fitness-adaptive mutation: scale by intensity; scale noise by parameter std\n        flip_base = 1e-4  # extremely small sign-flip probability\n        gprob = min(0.5, gauss_prob * intensity)\n        rsprob = min(0.05, reset_prob * (0.5 + 0.5 * intensity))\n        flip_prob = min(0.01, flip_base * intensity)\n\n        with torch.no_grad():\n            for p in model.parameters():\n                p_std = torch.std(p)\n                scale = (p_std if torch.isfinite(p_std) and p_std > 0 else torch.tensor(1.0, device=p.device))\n                # Gaussian perturbation\n                if gprob > 0.0:\n                    gmask = torch.rand_like(p) < gprob\n                    if gmask.any():\n                        noise = torch.randn_like(p) * (gauss_sigma * (0.5 + 0.75 * intensity)) * scale\n                        p[gmask] = p[gmask] + noise[gmask]\n                # Occasional reset\n                if rsprob > 0.0:\n                    rmask = torch.rand_like(p) < rsprob\n                    if rmask.any():\n                        p[rmask] = torch.randn_like(p[rmask]) * scale\n                # Rare sign flip to escape symmetry\n                if flip_prob > 0.0:\n                    fmask = torch.rand_like(p) < flip_prob\n                    if fmask.any():\n                        p[fmask] = -p[fmask]\n        return model\n\n    # Rank-based selection probabilities (exponential ranking)\n    sorted_idx = torch.argsort(scores, descending=True)\n    ranks = torch.empty(POP_SIZE, device=device, dtype=torch.float32)\n    ranks[sorted_idx] = torch.arange(POP_SIZE, device=device, dtype=torch.float32)\n    # Lower rank -> higher probability\n    weights = (1.0 - SELECTION_Q) ** ranks\n    weights = weights / (weights.sum() + 1e-12)\n\n    def select_index():\n        # Sample with replacement\n        idx = torch.multinomial(weights, 1, replacement=True)\n        return int(idx.item())\n\n    # Build next population\n    new_population = []\n\n    # Elites\n    for i in range(num_elite):\n        elite_idx = int(sorted_idx[i].item())\n        new_population.append(clone_model(current_population[elite_idx]))\n\n    # Immigrants (minimal when diversity is already high)\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children\n    for _ in range(num_children):\n        i1 = select_index()\n        i2 = select_index()\n        # Try to ensure different parents when possible\n        tries = 0\n        while i2 == i1 and tries < 3:\n            i2 = select_index()\n            tries += 1\n\n        p1 = current_population[i1]\n        p2 = current_population[i2]\n        s1 = scores[i1]\n        s2 = scores[i2]\n\n        # Crossover\n        child = crossover(p1, p2, s1, s2)\n\n        # Mutation intensity based on average rank (worse rank -> stronger mutation)\n        r1 = ranks[i1] / (POP_SIZE - 1 + 1e-8)\n        r2 = ranks[i2] / (POP_SIZE - 1 + 1e-8)\n        r_avg = float(((r1 + r2) * 0.5).item())\n        intensity = 0.6 + 1.6 * r_avg  # in [0.6, 2.2)\n\n        # Mutate\n        child = mutate(child, GAUSS_MUT_PROB, GAUSS_SIGMA, RESET_MUT_PROB, intensity=intensity)\n        new_population.append(child)\n\n    # Safety size adjustments\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            elite_idx = int(sorted_idx[i % num_elite].item())\n            extra = clone_model(current_population[elite_idx])\n            new_population.append(extra)\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 12.85%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 21.16%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 11.98%\n",
            "Finished evaluation. Operator 3 primary fitness: -11.4180\n",
            "\n",
            "--- Evaluating Operator Individual 5/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    '''\n    Holistic evolutionary operator with adaptive mutation, soft crossover, elitism, tournament selection,\n    and diversity-preserving random immigrants.\n    '''\n    POPULATION_SIZE = len(current_population)\n    ELITISM_RATE = 0.05\n    TOURNAMENT_SIZE = 3\n    IMMIGRANT_RATE = 0.05\n\n    # --- Diversity-adaptive mutation parameters (based on fitness spread) ---\n    best = torch.max(fitness_scores).item()\n    worst = torch.min(fitness_scores).item()\n    spread = best - worst\n    if spread < 0.10:\n        NOISE_P = 0.06\n        NOISE_STD_FACTOR = 0.25\n        RESET_PROB = 0.001\n    elif spread < 0.15:\n        NOISE_P = 0.03\n        NOISE_STD_FACTOR = 0.15\n        RESET_PROB = 0.0005\n    else:\n        NOISE_P = 0.015\n        NOISE_STD_FACTOR = 0.10\n        RESET_PROB = 0.0002\n\n    # --- Helpers ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def crossover(parent1, parent2):\n        # Smooth, per-weight blend crossover with random mixing coefficients\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        cdict = child.state_dict()\n        for k in p1.keys():\n            t1 = p1[k]\n            t2 = p2[k]\n            if t1.dtype.is_floating_point:\n                alpha = torch.rand_like(t1)\n                cdict[k] = alpha * t1 + (1.0 - alpha) * t2\n            else:\n                # For non-float buffers (e.g., counters), inherit from a random parent\n                take_from_p1 = torch.rand(()) < 0.5\n                cdict[k] = t1 if take_from_p1 else t2\n        child.load_state_dict(cdict)\n        return child\n\n    def mutate(model):\n        with torch.no_grad():\n            for p in model.parameters():\n                if not p.requires_grad:\n                    continue\n                # Scale noise to parameter scale\n                param_std = torch.std(p).item()\n                scaled_std = NOISE_STD_FACTOR * (param_std if param_std > 0 else 1.0)\n                mask = torch.rand_like(p) < NOISE_P\n                noise = torch.randn_like(p) * scaled_std\n                p.add_(noise * mask)\n                if RESET_PROB > 0:\n                    reset_mask = torch.rand_like(p) < RESET_PROB\n                    p.data[reset_mask] = torch.randn_like(p)[reset_mask] * (param_std if param_std > 0 else 1.0)\n        return model\n\n    def tournament_selection_idx(scores):\n        idxs = torch.randint(0, POPULATION_SIZE, (TOURNAMENT_SIZE,))\n        winner_local = torch.argmax(scores[idxs])\n        return int(idxs[winner_local].item())\n\n    # --- Build next population ---\n    sorted_indices = torch.argsort(fitness_scores, descending=True)\n    num_elite = max(1, int(POPULATION_SIZE * ELITISM_RATE))\n    num_immigrants = max(1, int(POPULATION_SIZE * IMMIGRANT_RATE))\n    num_children_to_create = POPULATION_SIZE - num_elite - num_immigrants\n    if num_children_to_create < 0:\n        num_children_to_create = 0\n        num_immigrants = POPULATION_SIZE - num_elite\n\n    new_population = []\n    # Elitism (deep-cloned to avoid accidental in-place modifications)\n    for i in range(num_elite):\n        elite = clone_model(current_population[int(sorted_indices[i].item())])\n        new_population.append(elite)\n\n    # Children via selection + crossover + mutation\n    for _ in range(num_children_to_create):\n        p1_idx = tournament_selection_idx(fitness_scores)\n        p2_idx = tournament_selection_idx(fitness_scores)\n        # Ensure two different parents when possible\n        attempts = 0\n        while p2_idx == p1_idx and attempts < 5 and POPULATION_SIZE > 1:\n            p2_idx = tournament_selection_idx(fitness_scores)\n            attempts += 1\n        parent1 = current_population[p1_idx]\n        parent2 = current_population[p2_idx]\n        child = crossover(parent1, parent2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Random immigrants to preserve exploration\n    for _ in range(num_immigrants):\n        immigrant = SimpleNet().to(device)\n        new_population.append(immigrant)\n\n    # Ensure population size (trim if any rounding issues)\n    if len(new_population) > POPULATION_SIZE:\n        new_population = new_population[:POPULATION_SIZE]\n    elif len(new_population) < POPULATION_SIZE:\n        # Fill missing with additional immigrants\n        for _ in range(POPULATION_SIZE - len(new_population)):\n            new_population.append(SimpleNet().to(device))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 12.25%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 15.44%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 12.22%\n",
            "Finished evaluation. Operator 5 primary fitness: -11.4744\n",
            "\n",
            "--- Evaluating Operator Individual 6/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Improved GA operator with adaptive selection pressure, arithmetic crossover,\n    and adaptive mixed mutation to preserve diversity while maintaining progress.\n    \"\"\"\n    POPULATION_SIZE = len(current_population)\n    ELITISM_RATE = 0.05\n\n    # Compute diversity (fitness spread) and derive adaptive parameters\n    scores_tensor = fitness_scores.detach()\n    spread = (scores_tensor.max() - scores_tensor.min()).item() if len(scores_tensor) > 0 else 0.0\n    # Diversity factor in [0,1]: higher when spread is low\n    f = max(0.0, min(1.0, (0.15 - spread) / 0.15))\n\n    # Adaptive selection pressure via tournament size\n    TOURNAMENT_SIZE = max(3, int(round(5 - 2 * f)))  # 5 -> 3 as diversity drops\n\n    # Adaptive mutation rates\n    P_GAUSS = 0.002 + 0.010 * f     # per-weight gaussian mutation prob\n    P_RESET = 0.0001 + 0.0009 * f   # per-weight reset prob\n    P_REINIT_TENSOR = 0.002 * f     # per-tensor reinit prob\n    MUT_INTENSITY = 1.0 + 0.5 * f   # noise scale multiplier\n\n    # Random immigrants to inject exploration when diversity is low\n    num_immigrants = int(POPULATION_SIZE * (0.05 * f))\n\n    # --- Helpers ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def tournament_selection(population, scores_cpu, k):\n        idx = torch.randint(0, len(population), (k,))\n        winner_local = torch.argmax(scores_cpu[idx])\n        return population[int(idx[winner_local].item())]\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        cd = child.state_dict()\n        for key in cd.keys():\n            t1 = p1[key]\n            t2 = p2[key]\n            if t1.dtype.is_floating_point:\n                # Arithmetic crossover with per-tensor alpha for stability\n                alpha = torch.empty(1, device=device).uniform_(0.3, 0.7).item()\n                mixed = t1 * alpha + t2 * (1.0 - alpha)\n                # With small chance, patch in pieces from a parent to keep discrete structure\n                if torch.rand((), device=device).item() < 0.1:\n                    mask = torch.rand_like(mixed) < 0.5\n                    mixed = torch.where(mask, t1, mixed)\n                cd[key] = mixed\n            else:\n                cd[key] = t1.clone()\n        child.load_state_dict(cd)\n        return child\n\n    def mutate(model, p_gauss, p_reset, p_reinit, intensity):\n        with torch.no_grad():\n            for name, param in model.named_parameters():\n                if not param.requires_grad:\n                    continue\n\n                # Occasional tensor reinitialization (helps escape local minima)\n                if torch.rand((), device=device).item() < p_reinit:\n                    if param.dim() >= 2:\n                        torch.nn.init.kaiming_normal_(param, nonlinearity='relu')\n                    else:\n                        param.zero_()\n                    continue\n\n                # Gaussian mutation on a subset of weights\n                if p_gauss > 0.0:\n                    mask = torch.rand_like(param) < p_gauss\n                    if mask.any():\n                        # Scale noise by parameter statistics\n                        std = param.std().item()\n                        if not (std > 0.0):\n                            std = 1.0\n                        sigma = 0.02 * std * intensity\n                        noise = torch.randn_like(param) * sigma\n                        param.add_(noise * mask)\n\n                # Reset mutation (rare, larger jumps)\n                if p_reset > 0.0:\n                    mask = torch.rand_like(param) < p_reset\n                    if mask.any():\n                        new_vals = torch.randn_like(param)\n                        param.data[mask] = new_vals[mask]\n        return model\n\n    # --- Main GA loop ---\n    scores_cpu = scores_tensor.detach().cpu()\n    sorted_indices = torch.argsort(scores_tensor, descending=True)\n    num_elite = int(max(1, round(POPULATION_SIZE * ELITISM_RATE)))\n\n    new_population = []\n    # Elitism: clone top performers to preserve them\n    for i in sorted_indices[:num_elite]:\n        new_population.append(clone_model(current_population[int(i.item())]))\n\n    # Children\n    num_children_to_create = POPULATION_SIZE - num_elite - num_immigrants\n    num_children_to_create = max(0, num_children_to_create)\n\n    for _ in range(num_children_to_create):\n        # Select parents with adaptive tournament size and encourage different parents\n        parent1 = tournament_selection(current_population, scores_cpu, TOURNAMENT_SIZE)\n        parent2 = tournament_selection(current_population, scores_cpu, TOURNAMENT_SIZE)\n        attempts = 0\n        while parent2 is parent1 and attempts < 3:\n            parent2 = tournament_selection(current_population, scores_cpu, TOURNAMENT_SIZE)\n            attempts += 1\n\n        child = crossover(parent1, parent2)\n        child = mutate(child, P_GAUSS, P_RESET, P_REINIT_TENSOR, MUT_INTENSITY)\n        new_population.append(child)\n\n    # Random immigrants (fresh individuals) to boost exploration when needed\n    for _ in range(num_immigrants):\n        immigrant = SimpleNet().to(device)\n        # Optionally small mutation to random init to diversify slightly\n        immigrant = mutate(immigrant, P_GAUSS * 0.5, P_RESET * 0.5, P_REINIT_TENSOR * 0.5, MUT_INTENSITY * 0.5)\n        new_population.append(immigrant)\n\n    # If rounding led to size mismatch, adjust by cloning best or trimming\n    if len(new_population) < POPULATION_SIZE:\n        deficit = POPULATION_SIZE - len(new_population)\n        for i in sorted_indices[:deficit]:\n            new_population.append(clone_model(current_population[int(i.item())]))\n    elif len(new_population) > POPULATION_SIZE:\n        new_population = new_population[:POPULATION_SIZE]\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 16.18%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 12.80%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 17.86%\n",
            "Finished evaluation. Operator 6 primary fitness: -11.3729\n",
            "\n",
            "--- Meta-Generation 2 Results ---\n",
            "Best Operator Fitness (Avg Final Best): -11.3403\n",
            "Best Performing Operator's Code:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with adaptive diversity control.\n    - Elitism with cloning\n    - Adaptive tournament size\n    - Dynamic crossover strategy (Uniform / BLX-alpha)\n    - Adaptive Gaussian and reset mutation\n    - Immigrants injection when diversity is low\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Guard for degenerate populations\n    if POP_SIZE == 0:\n        return []\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    low_diversity = cv.item() < 0.05\n    unstable = cv.item() > 0.5\n\n    # --- Adaptive hyperparameters ---\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        TOURNAMENT_SIZE = 3\n        GAUSS_MUT_PROB = 0.02\n        GAUSS_SIGMA = 0.10\n        RESET_MUT_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.05\n        CROSSOVER_MODE = \"blx\"  # BLX-alpha crossover to expand search\n        BLX_ALPHA = 0.20\n    elif unstable:\n        ELITISM_RATE = 0.07\n        TOURNAMENT_SIZE = 7\n        GAUSS_MUT_PROB = 0.006\n        GAUSS_SIGMA = 0.03\n        RESET_MUT_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.01\n        CROSSOVER_MODE = \"uniform\"  # stabilize around good schemas\n        BLX_ALPHA = 0.10\n    else:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 5\n        GAUSS_MUT_PROB = 0.01\n        GAUSS_SIGMA = 0.05\n        RESET_MUT_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.02\n        CROSSOVER_MODE = \"mixed\"  # combine uniform and arithmetic\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        c = child.state_dict()\n\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = p1[k]\n                t2 = p2[k]\n                if CROSSOVER_MODE == \"uniform\":\n                    mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                    c[k] = t1 * mask + t2 * (1.0 - mask)\n                elif CROSSOVER_MODE == \"blx\":\n                    c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                else:  # mixed\n                    # 50% uniform mask, 50% arithmetic blend with per-element alpha in [0.25, 0.75]\n                    if torch.rand((), device=device) < 0.5:\n                        mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                        c[k] = t1 * mask + t2 * (1.0 - mask)\n                    else:\n                        alpha = 0.25 + 0.5 * torch.rand_like(t1)\n                        c[k] = alpha * t1 + (1.0 - alpha) * t2\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, gauss_prob=GAUSS_MUT_PROB, gauss_sigma=GAUSS_SIGMA, reset_prob=RESET_MUT_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if gauss_prob > 0.0:\n                    gmask = torch.rand_like(p) < gauss_prob\n                    noise = torch.randn_like(p) * gauss_sigma\n                    p[gmask] = p[gmask] + noise[gmask]\n                if reset_prob > 0.0:\n                    rmask = torch.rand_like(p) < reset_prob\n                    new_vals = torch.randn_like(p)\n                    p[rmask] = new_vals[rmask]\n        return model\n\n    def tournament_selection(population, scores_tensor, size=TOURNAMENT_SIZE):\n        idxs = torch.randint(0, len(population), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = int(idxs[torch.argmax(sub_scores)].item())\n        return population[winner_idx]\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = []\n    for i in range(num_elite):\n        elites.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    new_population = list(elites)\n\n    # Immigrants (fresh random individuals) for diversity\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        p1 = tournament_selection(current_population, scores)\n        # ensure different parents where possible\n        p2 = p1\n        attempts = 0\n        while p2 is p1 and attempts < 3:\n            p2 = tournament_selection(current_population, scores)\n            attempts += 1\n\n        child = crossover(p1, p2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if rounding errors occur, adjust size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # Fill up with additional mutated clones of elites\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            extra = clone_model(current_population[int(sorted_idx[i % len(sorted_idx)].item())])\n            new_population.append(mutate(extra))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Operator's Performance Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This operator's performance has been recorded over **3** separate runs.\nThe table below shows the fitness dynamics, **averaged across all runs**.\nFitness is based on the negative loss on training batches (higher is better).\n\n| Gen | Best Fitness | Avg Fitness  | Worst Fitness | Spread (Diversity) |\n|:---:|:------------:|:------------:|:-------------:|:------------------:|\n|  0  |     -11.4630 |     -11.5397 |      -11.6121 |             0.1491 |\n|  1  |     -11.4313 |     -11.5767 |      -12.1839 |             0.7526 |\n|  2  |     -11.4298 |     -11.5916 |      -11.9507 |             0.5209 |\n|  3  |     -11.3812 |     -11.6047 |      -11.9569 |             0.5757 |\n|  4  |     -11.3890 |     -11.6302 |      -12.2664 |             0.8774 |\n|  5  |     -11.3751 |     -11.6719 |      -13.6228 |             2.2477 |\n|  6  |     -11.3837 |     -11.6159 |      -12.1176 |             0.7339 |\n|  7  |     -11.3677 |     -11.6666 |      -12.3902 |             1.0226 |\n|  8  |     -11.3426 |     -11.6645 |      -12.4404 |             1.0978 |\n|  9  |     -11.3403 |     -11.6956 |      -13.2220 |             1.8817 |\n\n**Analysis Hints for Your Evolution:**\n- **Rate of Improvement:** Analyze the slope of the `Best Fitness` column. A steep, consistent increase is ideal.\n- **Population Diversity:** The `Spread (Best-Worst)` column is a proxy for diversity. If it collapses to near-zero too quickly, the population has prematurely converged, and you should consider changes that increase exploration (e.g., higher mutation, different selection).\n- **Stability:** Smooth, predictable improvements indicate a stable operator. Jagged or erratic values might suggest the operator is too chaotic."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "--- Calling Google API to evolve operator (with generational feedback) ---\n",
            "--- Calling Google API to evolve operator (with generational feedback) ---\n",
            "\n",
            "========================= META-GENERATION 3/4 =========================\n",
            "Evolving the `generate_next_population` operator...\n",
            "\n",
            "--- Evaluating Operator Individual 4/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with stability-focused adaptation.\n    - Rank-based adaptive mutation intensity\n    - Tournament selection with regime-aware pressure\n    - Simulated Binary Crossover (SBX) for controlled exploration\n    - Per-parameter scale-aware Gaussian mutation\n    - Guided immigrants only when diversity is low\n    \"\"\"\n    POP_SIZE = len(current_population)\n    if POP_SIZE == 0:\n        return []\n\n    # Prepare fitness tensor\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Diversity diagnostics\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = (std / (torch.abs(mean) + 1e-8)).clamp(min=0.0).item()\n\n    # Regimes\n    low_diversity = cv < 0.06\n    unstable = cv > 0.35\n\n    # Adaptive hyperparameters\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        TOURNAMENT_SIZE = 3\n        BASE_MUT_PROB = 0.02\n        BASE_MUT_SIGMA = 0.12\n        RESET_MUT_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.06\n        SBX_ETA = 5.0  # more exploratory\n    elif unstable:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 6\n        BASE_MUT_PROB = 0.004\n        BASE_MUT_SIGMA = 0.02\n        RESET_MUT_PROB = 0.0\n        IMMIGRANTS_RATE = 0.0\n        SBX_ETA = 15.0  # conservative crossover\n    else:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 4\n        BASE_MUT_PROB = 0.01\n        BASE_MUT_SIGMA = 0.05\n        RESET_MUT_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.01\n        SBX_ETA = 10.0\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # Rank-based intensity shaping: rank 0 (best) -> 0.0, worst -> 1.0\n    sorted_idx = torch.argsort(scores, descending=True)\n    ranks = torch.empty_like(sorted_idx, dtype=torch.float32)\n    if POP_SIZE > 1:\n        ranks[sorted_idx] = torch.linspace(0.0, 1.0, steps=POP_SIZE, device=device)\n    else:\n        ranks[sorted_idx] = 0.0\n\n    # Utilities\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def sbx_tensor(p1, p2, eta):\n        # Simulated Binary Crossover for tensors\n        u = torch.rand_like(p1)\n        one = torch.ones_like(u)\n        two = one * 2.0\n        inv = 1.0 / (eta + 1.0)\n        beta = torch.where(\n            u <= 0.5,\n            (two * u) ** inv,\n            (one / (two * (1.0 - u))) ** inv,\n        )\n        c1 = 0.5 * ((1 + beta) * p1 + (1 - beta) * p2)\n        c2 = 0.5 * ((1 - beta) * p1 + (1 + beta) * p2)\n        # pick per-element between c1 and c2 to avoid bias\n        pick_mask = (torch.rand_like(u) < 0.5)\n        return torch.where(pick_mask, c1, c2)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        sd1 = parent1.state_dict()\n        sd2 = parent2.state_dict()\n        c = child.state_dict()\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = sd1[k]\n                t2 = sd2[k]\n                # Apply SBX; for very small tensors (e.g., biases), fallback to simple average with jitter\n                if t1.numel() >= 4:\n                    c[k] = sbx_tensor(t1, t2, SBX_ETA)\n                else:\n                    alpha = 0.5\n                    blended = alpha * t1 + (1.0 - alpha) * t2\n                    jitter = 0.01 * torch.randn_like(blended)\n                    c[k] = blended + jitter\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, base_prob, base_sigma, reset_prob, intensity_scale=1.0):\n        # intensity_scale adjusts both probability and sigma per individual\n        prob = float(torch.clamp(torch.tensor(base_prob * intensity_scale, device=device), 1e-6, 0.5).item())\n        sigma_scale = float(torch.clamp(torch.tensor(intensity_scale, device=device), 0.25, 2.0).item())\n        with torch.no_grad():\n            for p in model.parameters():\n                # Per-parameter scale-aware sigma\n                p_std = p.detach().std()\n                # fallback scale if near-constant tensor\n                eff_std = p_std if torch.isfinite(p_std) and p_std > 1e-6 else torch.tensor(1.0, device=device)\n                eff_sigma = base_sigma * sigma_scale * eff_std\n                if prob > 0.0:\n                    gmask = (torch.rand_like(p) < prob)\n                    if torch.any(gmask):\n                        noise = torch.randn_like(p) * eff_sigma\n                        p[gmask] = p[gmask] + noise[gmask]\n                if reset_prob > 0.0:\n                    rprob = float(torch.clamp(torch.tensor(reset_prob * intensity_scale, device=device), 0.0, 0.05).item())\n                    if rprob > 0.0:\n                        rmask = (torch.rand_like(p) < rprob)\n                        if torch.any(rmask):\n                            # reset around 0 with variance relative to eff_std to avoid extreme outliers\n                            new_vals = torch.randn_like(p) * (eff_std * 2.0)\n                            p[rmask] = new_vals[rmask]\n        return model\n\n    def tournament_selection_index(pop, scores_tensor, size):\n        idxs = torch.randint(0, len(pop), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = int(idxs[torch.argmax(sub_scores)].item())\n        return winner_idx\n\n    # Build elites\n    elites = []\n    for i in range(num_elite):\n        elites.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    new_population = list(elites)\n\n    # Guided immigrants for diversity (only when configured)\n    def guided_immigrant():\n        # Mix: half fresh random, half heavily mutated clone of a random parent\n        if torch.rand((), device=device) < 0.5:\n            return SimpleNet().to(device)\n        else:\n            ridx = int(torch.randint(0, POP_SIZE, (1,), device=device).item())\n            m = clone_model(current_population[ridx])\n            return mutate(m, base_prob=max(BASE_MUT_PROB, 0.015), base_sigma=max(BASE_MUT_SIGMA, 0.10), reset_prob=max(RESET_MUT_PROB, 5e-4), intensity_scale=2.0)\n\n    for _ in range(num_immigrants):\n        new_population.append(guided_immigrant())\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        p1_idx = tournament_selection_index(current_population, scores, TOURNAMENT_SIZE)\n        p2_idx = p1_idx\n        attempts = 0\n        while p2_idx == p1_idx and attempts < 4:\n            p2_idx = tournament_selection_index(current_population, scores, TOURNAMENT_SIZE)\n            attempts += 1\n\n        p1 = current_population[p1_idx]\n        p2 = current_population[p2_idx]\n\n        # Parent-quality-based mutation intensity (0 best -> 0.7, worst -> 1.3)\n        r1 = ranks[p1_idx].item()\n        r2 = ranks[p2_idx].item()\n        rmean = (r1 + r2) * 0.5\n        intensity = 0.7 + 0.6 * rmean\n\n        child = crossover(p1, p2)\n        child = mutate(child, base_prob=BASE_MUT_PROB, base_sigma=BASE_MUT_SIGMA, reset_prob=RESET_MUT_PROB, intensity_scale=float(intensity))\n        new_population.append(child)\n\n    # Adjust to exact size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            elite_src = current_population[int(sorted_idx[i % len(sorted_idx)].item())]\n            extra = clone_model(elite_src)\n            new_population.append(mutate(extra, base_prob=BASE_MUT_PROB, base_sigma=BASE_MUT_SIGMA, reset_prob=RESET_MUT_PROB, intensity_scale=1.0))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting 3 detailed evaluation runs for this operator...\n",
            "  > Run 1/3...\n",
            "    Run 1 finished. Final test accuracy of best model: 10.38%\n",
            "  > Run 2/3...\n",
            "    Run 2 finished. Final test accuracy of best model: 17.03%\n",
            "  > Run 3/3...\n",
            "    Run 3 finished. Final test accuracy of best model: 16.77%\n",
            "Finished evaluation. Operator 4 primary fitness: -11.3768\n",
            "\n",
            "--- Evaluating Operator Individual 5/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\n```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Evolved holistic evolutionary operator.\n    - Elitism to preserve best solutions.\n    - Linear Rank Selection for stable selection pressure.\n    - Hybrid crossover (Uniform/Arithmetic) for balanced gene exchange.\n    - Multi-stage mutation (Creep, Gaussian, Reset) for fine-tuning and exploration.\n    - Adaptive hyperparameters based on population diversity (CV).\n    - Immigrant injection to prevent long-term stagnation.\n    \"\"\"\n    POP_SIZE = len(current_population)\n    if POP_SIZE == 0:\n        return []\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    # --- Adaptive hyperparameters based on diversity ---\n    if cv.item() < 0.03:  # Low diversity: Increase exploration\n        ELITISM_RATE = 0.05\n        SELECTION_PRESSURE = 1.3  # Closer to uniform random\n        CREEP_PROB, CREEP_SIGMA = 0.02, 0.03\n        GAUSS_PROB, GAUSS_SIGMA = 0.01, 0.10\n        RESET_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.10\n    elif cv.item() > 0.3:  # High diversity: Increase exploitation\n        ELITISM_RATE = 0.15\n        SELECTION_PRESSURE = 1.8  # Stronger selection\n        CREEP_PROB, CREEP_SIGMA = 0.05, 0.01\n        GAUSS_PROB, GAUSS_SIGMA = 0.005, 0.05\n        RESET_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.01\n    else:  # Balanced state\n        ELITISM_RATE = 0.10\n        SELECTION_PRESSURE = 1.6\n        CREEP_PROB, CREEP_SIGMA = 0.04, 0.02\n        GAUSS_PROB, GAUSS_SIGMA = 0.008, 0.08\n        RESET_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.03\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1_sd = parent1.state_dict()\n        p2_sd = parent2.state_dict()\n        c_sd = child.state_dict()\n\n        with torch.no_grad():\n            for k in c_sd.keys():\n                t1, t2 = p1_sd[k], p2_sd[k]\n                # Hybrid: 50% chance of uniform crossover, 50% arithmetic per tensor\n                if torch.rand(()) < 0.5:\n                    mask = torch.rand_like(t1) < 0.5\n                    c_sd[k].copy_(torch.where(mask, t1, t2))\n                else:\n                    alpha = torch.rand((), device=device)\n                    c_sd[k].copy_(alpha * t1 + (1.0 - alpha) * t2)\n        child.load_state_dict(c_sd)\n        return child\n\n    def mutate(model):\n        with torch.no_grad():\n            for p in model.parameters():\n                # 1. Creep mutation (fine-tuning)\n                if CREEP_PROB > 0:\n                    mask = torch.rand_like(p) < CREEP_PROB\n                    noise = torch.randn_like(p) * CREEP_SIGMA\n                    p.add_(noise * mask)\n                # 2. Gaussian mutation (larger jumps)\n                if GAUSS_PROB > 0:\n                    mask = torch.rand_like(p) < GAUSS_PROB\n                    noise = torch.randn_like(p) * GAUSS_SIGMA\n                    p.add_(noise * mask)\n                # 3. Reset mutation (radical exploration)\n                if RESET_PROB > 0:\n                    mask = torch.rand_like(p) < RESET_PROB\n                    new_vals = torch.randn_like(p) * p.std() # scale to layer's current variance\n                    p[mask] = new_vals[mask]\n        return model\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    \n    # 1. Elitism\n    elites = [clone_model(current_population[i.item()]) for i in sorted_idx[:num_elite]]\n    new_population = list(elites)\n\n    # 2. Immigrants (fresh random individuals)\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n    \n    # --- Setup for Rank Selection ---\n    s = SELECTION_PRESSURE\n    ranks_zero_based = torch.arange(POP_SIZE, dtype=torch.float32, device=device)\n    # Linear ranking probability calculation\n    probs = (s - (2 * s - 2) * ranks_zero_based / (POP_SIZE - 1)) / POP_SIZE\n    if not torch.all(probs >= 0): # Safety check for floating point issues\n        probs = torch.ones_like(probs) / POP_SIZE\n\n    # 3. Children via selection, crossover, mutation\n    for _ in range(num_children):\n        # Select parents using rank-based probabilities\n        parent_indices = torch.multinomial(probs, num_samples=2, replacement=True)\n        p1_orig_idx = sorted_idx[parent_indices[0]].item()\n        p2_orig_idx = sorted_idx[parent_indices[1]].item()\n        \n        p1 = current_population[p1_orig_idx]\n        p2 = current_population[p2_orig_idx]\n        \n        child = crossover(p1, p2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: Adjust size if rounding errors occur\n    while len(new_population) < POP_SIZE:\n        # Fill with mutated clones of the best individuals\n        extra_child = clone_model(elites[len(new_population) % len(elites)])\n        new_population.append(mutate(extra_child))\n    \n    return new_population[:POP_SIZE]\n```\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error executing evolved code. Attempting LLM repair (1/1).\n",
            "--- Calling Google API to repair operator ---\n",
            "Error executing evolved code after repair attempts: invalid syntax (<string>, line 1)\n",
            "Finished evaluation. Operator 5 failed and was assigned a fitness of -inf.\n",
            "\n",
            "--- Evaluating Operator Individual 6/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\n```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Evolved GA operator. Increases selection pressure and uses uniform crossover\n    to enhance exploitation, while maintaining adaptive mutation for exploration.\n    Aims for faster convergence based on the slow but steady progress observed.\n    \"\"\"\n    # --- Tunable Parameters ---\n    POPULATION_SIZE = len(current_population)\n    # Increased elitism to preserve more top performers and accelerate exploitation.\n    ELITISM_RATE = 0.10\n\n    # --- Adaptive Parameter Calculation ---\n    scores_tensor = fitness_scores.detach()\n    spread = (scores_tensor.max() - scores_tensor.min()).item() if len(scores_tensor) > 0 else 0.0\n    # Diversity factor in [0,1]: higher when spread is low.\n    # The threshold is slightly lowered to be more responsive.\n    f = max(0.0, min(1.0, (0.12 - spread) / 0.12))\n\n    # Increased base selection pressure to favor fitter individuals more strongly.\n    # Pressure reduces as diversity drops to allow for recovery.\n    TOURNAMENT_SIZE = max(3, int(round(6 - 3 * f)))\n\n    # Simplified and strengthened adaptive mutation scheme.\n    # Higher base mutation rate for more consistent exploration.\n    P_MUTATION = 0.004 + 0.01 * f\n    # Given a mutation, a small chance it's a large \"reset\" jump.\n    P_RESET_GIVEN_MUTATION = 0.05\n    # Adaptive mutation intensity for Gaussian noise.\n    MUT_INTENSITY = 0.5 + 1.5 * f\n\n    # Random immigrants remain a key mechanism to inject diversity when stagnating.\n    num_immigrants = int(POPULATION_SIZE * (0.05 * f))\n\n    # --- Helper Functions ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def tournament_selection(population, scores_cpu, k):\n        # Standard tournament selection: select k random individuals and return the best one.\n        idx = torch.randint(0, len(population), (k,))\n        winner_local_idx = torch.argmax(scores_cpu[idx])\n        return population[int(idx[winner_local_idx].item())]\n\n    def uniform_crossover(parent1, parent2):\n        \"\"\"\n        Performs uniform crossover. For each weight, a random choice is made\n        to take the weight from either parent1 or parent2. This preserves learned\n        \"building blocks\" (groups of co-adapted weights) better than averaging.\n        \"\"\"\n        child = SimpleNet().to(device)\n        p1_sd = parent1.state_dict()\n        p2_sd = parent2.state_dict()\n        child_sd = child.state_dict()\n\n        for key in child_sd.keys():\n            t1 = p1_sd[key]\n            t2 = p2_sd[key]\n            if t1.dtype.is_floating_point:\n                # Create a binary mask to select genes from parents.\n                mask = torch.rand_like(t1) < 0.5\n                child_sd[key] = torch.where(mask, t1, t2)\n            else:\n                # For non-floating point params (e.g., batchnorm stats), just copy from parent1.\n                child_sd[key] = t1.clone()\n\n        child.load_state_dict(child_sd)\n        return child\n\n    def mutate(model):\n        \"\"\"\n        Applies mutation based on a single probability P_MUTATION.\n        Mutated weights are either perturbed by scaled Gaussian noise or reset completely.\n        \"\"\"\n        with torch.no_grad():\n            for param in model.parameters():\n                if not param.requires_grad:\n                    continue\n\n                # Create a single mask for all mutations on this tensor.\n                mutation_mask = torch.rand_like(param) < P_MUTATION\n                if not mutation_mask.any():\n                    continue\n\n                # Decide which of the selected weights get reset vs. perturbed.\n                reset_mask = (torch.rand_like(param) < P_RESET_GIVEN_MUTATION) & mutation_mask\n\n                # Apply Gaussian perturbation (on non-reset weights).\n                gauss_mask = mutation_mask & ~reset_mask\n                if gauss_mask.any():\n                    std = param.std().item()\n                    if not (std > 0.0): std = 1.0 # Avoid division by zero\n                    sigma = 0.1 * std * MUT_INTENSITY # Noise scaled by weight std and adaptive intensity\n                    noise = torch.randn_like(param) * sigma\n                    param.add_(noise * gauss_mask)\n\n                # Apply reset mutation (large jump).\n                if reset_mask.any():\n                    new_vals = torch.randn_like(param)\n                    param.data[reset_mask] = new_vals[reset_mask]\n        return model\n\n    # --- Main GA Execution ---\n    scores_cpu = scores_tensor.detach().cpu()\n    sorted_indices = torch.argsort(scores_tensor, descending=True)\n    num_elite = int(max(1, round(POPULATION_SIZE * ELITISM_RATE)))\n\n    new_population = []\n    # 1. Elitism: Directly copy the best individuals to the next generation.\n    for i in sorted_indices[:num_elite]:\n        new_population.append(clone_model(current_population[int(i.item())]))\n\n    # 2. Crossover & Mutation: Create the bulk of the new generation.\n    num_children_to_create = POPULATION_SIZE - num_elite - num_immigrants\n    num_children_to_create = max(0, num_children_to_create)\n\n    for _ in range(num_children_to_create):\n        # Select parents using the stronger tournament selection.\n        parent1 = tournament_selection(current_population, scores_cpu, TOURNAMENT_SIZE)\n        parent2 = tournament_selection(current_population, scores_cpu, TOURNAMENT_SIZE)\n        attempts = 0\n        while parent2 is parent1 and attempts < 5: # Encourage different parents\n            parent2 = tournament_selection(current_population, scores_cpu, TOURNAMENT_SIZE)\n            attempts += 1\n\n        child = uniform_crossover(parent1, parent2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # 3. Immigration: Add fresh, random individuals if diversity is low.\n    for _ in range(num_immigrants):\n        immigrant = SimpleNet().to(device)\n        new_population.append(immigrant)\n\n    # 4. Fill to size: Ensure population size is constant.\n    while len(new_population) < POPULATION_SIZE:\n        # If there's a deficit due to rounding, fill with clones of the absolute best.\n        best_clone = clone_model(current_population[int(sorted_indices[0].item())])\n        new_population.append(best_clone)\n    if len(new_population) > POPULATION_SIZE:\n        new_population = new_population[:POPULATION_SIZE]\n\n    return new_population\n```\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error executing evolved code. Attempting LLM repair (1/1).\n",
            "--- Calling Openai API to repair operator ---\n",
            "Error executing evolved code after repair attempts: invalid syntax (<string>, line 1)\n",
            "Finished evaluation. Operator 6 failed and was assigned a fitness of -inf.\n",
            "\n",
            "--- Meta-Generation 3 Results ---\n",
            "Best Operator Fitness (Avg Final Best): -11.3403\n",
            "Best Performing Operator's Code:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with adaptive diversity control.\n    - Elitism with cloning\n    - Adaptive tournament size\n    - Dynamic crossover strategy (Uniform / BLX-alpha)\n    - Adaptive Gaussian and reset mutation\n    - Immigrants injection when diversity is low\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Guard for degenerate populations\n    if POP_SIZE == 0:\n        return []\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    low_diversity = cv.item() < 0.05\n    unstable = cv.item() > 0.5\n\n    # --- Adaptive hyperparameters ---\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        TOURNAMENT_SIZE = 3\n        GAUSS_MUT_PROB = 0.02\n        GAUSS_SIGMA = 0.10\n        RESET_MUT_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.05\n        CROSSOVER_MODE = \"blx\"  # BLX-alpha crossover to expand search\n        BLX_ALPHA = 0.20\n    elif unstable:\n        ELITISM_RATE = 0.07\n        TOURNAMENT_SIZE = 7\n        GAUSS_MUT_PROB = 0.006\n        GAUSS_SIGMA = 0.03\n        RESET_MUT_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.01\n        CROSSOVER_MODE = \"uniform\"  # stabilize around good schemas\n        BLX_ALPHA = 0.10\n    else:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 5\n        GAUSS_MUT_PROB = 0.01\n        GAUSS_SIGMA = 0.05\n        RESET_MUT_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.02\n        CROSSOVER_MODE = \"mixed\"  # combine uniform and arithmetic\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        c = child.state_dict()\n\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = p1[k]\n                t2 = p2[k]\n                if CROSSOVER_MODE == \"uniform\":\n                    mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                    c[k] = t1 * mask + t2 * (1.0 - mask)\n                elif CROSSOVER_MODE == \"blx\":\n                    c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                else:  # mixed\n                    # 50% uniform mask, 50% arithmetic blend with per-element alpha in [0.25, 0.75]\n                    if torch.rand((), device=device) < 0.5:\n                        mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                        c[k] = t1 * mask + t2 * (1.0 - mask)\n                    else:\n                        alpha = 0.25 + 0.5 * torch.rand_like(t1)\n                        c[k] = alpha * t1 + (1.0 - alpha) * t2\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, gauss_prob=GAUSS_MUT_PROB, gauss_sigma=GAUSS_SIGMA, reset_prob=RESET_MUT_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if gauss_prob > 0.0:\n                    gmask = torch.rand_like(p) < gauss_prob\n                    noise = torch.randn_like(p) * gauss_sigma\n                    p[gmask] = p[gmask] + noise[gmask]\n                if reset_prob > 0.0:\n                    rmask = torch.rand_like(p) < reset_prob\n                    new_vals = torch.randn_like(p)\n                    p[rmask] = new_vals[rmask]\n        return model\n\n    def tournament_selection(population, scores_tensor, size=TOURNAMENT_SIZE):\n        idxs = torch.randint(0, len(population), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = int(idxs[torch.argmax(sub_scores)].item())\n        return population[winner_idx]\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = []\n    for i in range(num_elite):\n        elites.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    new_population = list(elites)\n\n    # Immigrants (fresh random individuals) for diversity\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        p1 = tournament_selection(current_population, scores)\n        # ensure different parents where possible\n        p2 = p1\n        attempts = 0\n        while p2 is p1 and attempts < 3:\n            p2 = tournament_selection(current_population, scores)\n            attempts += 1\n\n        child = crossover(p1, p2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if rounding errors occur, adjust size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # Fill up with additional mutated clones of elites\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            extra = clone_model(current_population[int(sorted_idx[i % len(sorted_idx)].item())])\n            new_population.append(mutate(extra))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Operator's Performance Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This operator's performance has been recorded over **3** separate runs.\nThe table below shows the fitness dynamics, **averaged across all runs**.\nFitness is based on the negative loss on training batches (higher is better).\n\n| Gen | Best Fitness | Avg Fitness  | Worst Fitness | Spread (Diversity) |\n|:---:|:------------:|:------------:|:-------------:|:------------------:|\n|  0  |     -11.4630 |     -11.5397 |      -11.6121 |             0.1491 |\n|  1  |     -11.4313 |     -11.5767 |      -12.1839 |             0.7526 |\n|  2  |     -11.4298 |     -11.5916 |      -11.9507 |             0.5209 |\n|  3  |     -11.3812 |     -11.6047 |      -11.9569 |             0.5757 |\n|  4  |     -11.3890 |     -11.6302 |      -12.2664 |             0.8774 |\n|  5  |     -11.3751 |     -11.6719 |      -13.6228 |             2.2477 |\n|  6  |     -11.3837 |     -11.6159 |      -12.1176 |             0.7339 |\n|  7  |     -11.3677 |     -11.6666 |      -12.3902 |             1.0226 |\n|  8  |     -11.3426 |     -11.6645 |      -12.4404 |             1.0978 |\n|  9  |     -11.3403 |     -11.6956 |      -13.2220 |             1.8817 |\n\n**Analysis Hints for Your Evolution:**\n- **Rate of Improvement:** Analyze the slope of the `Best Fitness` column. A steep, consistent increase is ideal.\n- **Population Diversity:** The `Spread (Best-Worst)` column is a proxy for diversity. If it collapses to near-zero too quickly, the population has prematurely converged, and you should consider changes that increase exploration (e.g., higher mutation, different selection).\n- **Stability:** Smooth, predictable improvements indicate a stable operator. Jagged or erratic values might suggest the operator is too chaotic."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "\n",
            "========================= META-GENERATION 4/4 =========================\n",
            "Evolving the `generate_next_population` operator...\n",
            "\n",
            "--- Evaluating Operator Individual 6/6 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\n```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with stability-aware exploitation and adaptive exploration.\n    - Rank/softmax selection with adaptive temperature\n    - Parent-biased blend crossover with optional BLX-alpha mixing\n    - Scale-aware Gaussian mutation with per-offspring intensity\n    - Elitism and elite-neighborhood exploitation\n    - Adaptive immigrants injection based on diversity/instability\n    \"\"\"\n    POP_SIZE = len(current_population)\n    if POP_SIZE == 0:\n        return []\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # --- Statistics & diagnostics ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    best = torch.max(scores)\n    worst = torch.min(scores)\n    spread = (best - worst).abs()\n    denom = torch.clamp(torch.abs(mean), min=1e-6)\n    rel_std = std / denom\n    rel_spread = spread / denom\n\n    # Heuristics from observed dynamics: sometimes large spread causes poor average\n    low_diversity = (rel_spread.item() < 0.06) or (rel_std.item() < 0.06)\n    high_instability = (rel_spread.item() > 0.16) or (rel_std.item() > 0.14)\n\n    # --- Adaptive hyperparameters ---\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        IMMIGRANTS_RATE = 0.08\n        EXPLOIT_RATE = 0.15  # mutated elite-neighborhood offspring\n        TEMP = 1.25  # softer selection to promote exploration\n        BASE_GAUSS_PROB = 0.020\n        BASE_GAUSS_SIGMA = 0.10\n        RESET_PROB = 5e-4\n        BLX_ALPHA = 0.30\n        BLX_RATIO = 0.60\n        EXPLOIT_INTENSITY = 0.8\n        EXPLORE_INTENSITY = 1.5\n    elif high_instability:\n        ELITISM_RATE = 0.14\n        IMMIGRANTS_RATE = 0.005\n        EXPLOIT_RATE = 0.35  # push toward strong regions to lift average\n        TEMP = 0.70  # stronger selection\n        BASE_GAUSS_PROB = 0.006\n        BASE_GAUSS_SIGMA = 0.030\n        RESET_PROB = 1e-5\n        BLX_ALPHA = 0.08\n        BLX_RATIO = 0.20\n        EXPLOIT_INTENSITY = 0.5\n        EXPLORE_INTENSITY = 0.9\n    else:\n        ELITISM_RATE = 0.12\n        IMMIGRANTS_RATE = 0.015\n        EXPLOIT_RATE = 0.25\n        TEMP = 0.90\n        BASE_GAUSS_PROB = 0.010\n        BASE_GAUSS_SIGMA = 0.050\n        RESET_PROB = 1e-4\n        BLX_ALPHA = 0.15\n        BLX_RATIO = 0.35\n        EXPLOIT_INTENSITY = 0.6\n        EXPLORE_INTENSITY = 1.1\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    remaining = POP_SIZE - num_elite - num_immigrants\n    num_exploit_children = max(0, int(remaining * EXPLOIT_RATE))\n    num_crossover_children = max(0, remaining - num_exploit_children)\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def parent_biased_blend(child, p1, p2, f1, f2, blx_ratio=BLX_RATIO, blx_alpha=BLX_ALPHA):\n        sd1 = p1.state_dict()\n        sd2 = p2.state_dict()\n        sc = child.state_dict()\n        # Compute bias toward better parent\n        # Normalize by observed std to be scale-aware; fallback if std small\n        scale = float(std.item() if std.item() > 1e-6 else 1.0)\n        adv = float((f1 - f2).item()) / (2.0 * scale)\n        # bias in [0.35, 0.65] skewed toward better parent\n        base_bias = 0.5 + 0.15 * torch.tanh(torch.tensor(adv, device=device)).item()\n\n        with torch.no_grad():\n            for k in sc.keys():\n                t1 = sd1[k]\n                t2 = sd2[k]\n                if not (t1.is_floating_point() and t2.is_floating_point()):\n                    # Non-floating buffers (e.g., counters) - inherit from better parent\n                    sc[k] = t1 if f1 >= f2 else t2\n                    continue\n                if torch.rand((), device=device) < blx_ratio:\n                    sc[k] = blx_alpha_tensor(t1, t2, blx_alpha)\n                else:\n                    # Per-tensor noisy bias\n                    # alpha tensor around base_bias with small noise, clipped to [0.05,0.95]\n                    noise = 0.10 * torch.randn_like(t1)\n                    alpha_tensor = torch.clamp(base_bias + noise, 0.05, 0.95)\n                    sc[k] = alpha_tensor * t1 + (1.0 - alpha_tensor) * t2\n        child.load_state_dict(sc)\n        return child\n\n    def mutate(model, base_gauss_prob, base_sigma, reset_prob, intensity=1.0):\n        with torch.no_grad():\n            for p in model.parameters():\n                if not p.is_floating_point():\n                    continue\n                layer_std = torch.std(p).detach()\n                # scale-aware sigma\n                sigma = base_sigma * (layer_std + 1e-3) * float(intensity)\n                gprob = min(0.5, base_gauss_prob * (0.5 + float(intensity)))\n                if gprob > 0.0:\n                    gmask = torch.rand_like(p) < gprob\n                    noise = torch.randn_like(p) * sigma\n                    p.add_(noise * gmask)\n                rprob = min(0.2, reset_prob * (0.5 + float(intensity)))\n                if rprob > 0.0:\n                    rmask = torch.rand_like(p) < rprob\n                    new_vals = torch.randn_like(p) * (layer_std + 1e-3)\n                    p[rmask] = new_vals[rmask]\n                # small shrinkage for stability\n                p.mul_(1.0 - 0.001 * min(2.0, float(intensity)))\n        return model\n\n    # Selection probabilities via softmax (Boltzmann selection)\n    # Higher TEMP -> flatter, lower TEMP -> greedier\n    logits = scores / float(max(TEMP, 1e-6))\n    probs = torch.softmax(logits - torch.max(logits), dim=0)\n\n    def sample_parent_index():\n        idx = torch.multinomial(probs, 1).item()\n        return idx\n\n    # Rank info for exploitation pool\n    sorted_idx = torch.argsort(scores, descending=True)\n    top_pool_size = max(2, int(0.30 * POP_SIZE))\n    top_pool = sorted_idx[:top_pool_size]\n\n    # --- Build next population ---\n    new_population = []\n\n    # Elites (pure clones)\n    for i in range(num_elite):\n        new_population.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    # Exploitation: mutated clones from top pool (micro to moderate intensity)\n    for _ in range(num_exploit_children):\n        src_idx = int(top_pool[torch.randint(0, top_pool_size, (1,), device=device)].item())\n        offspring = clone_model(current_population[src_idx])\n        offspring = mutate(offspring, BASE_GAUSS_PROB, BASE_GAUSS_SIGMA, RESET_PROB, intensity=EXPLOIT_INTENSITY)\n        new_population.append(offspring)\n\n    # Crossover + mutation children\n    for _ in range(num_crossover_children):\n        # ensure different parents where possible\n        p1_idx = sample_parent_index()\n        p2_idx = p1_idx\n        attempts = 0\n        while (p2_idx == p1_idx) and (attempts < 5):\n            p2_idx = sample_parent_index()\n            attempts += 1\n\n        parent1 = current_population[p1_idx]\n        parent2 = current_population[p2_idx]\n        f1 = scores[p1_idx]\n        f2 = scores[p2_idx]\n\n        child = SimpleNet().to(device)\n        child = parent_biased_blend(child, parent1, parent2, f1, f2)\n        child = mutate(child, BASE_GAUSS_PROB, BASE_GAUSS_SIGMA, RESET_PROB, intensity=EXPLORE_INTENSITY)\n        new_population.append(child)\n\n    # Immigrants for exploration\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Safety adjustments\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # fill with additional mutated elite clones\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            idx = int(sorted_idx[i % len(sorted_idx)].item())\n            extra = clone_model(current_population[idx])\n            extra = mutate(extra, BASE_GAUSS_PROB, BASE_GAUSS_SIGMA, RESET_PROB, intensity=EXPLOIT_INTENSITY)\n            new_population.append(extra)\n\n    return new_population\n```\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error executing evolved code. Attempting LLM repair (1/1).\n",
            "--- Calling Openai API to repair operator ---\n",
            "Error executing evolved code after repair attempts: invalid syntax (<string>, line 1)\n",
            "Finished evaluation. Operator 6 failed and was assigned a fitness of -inf.\n",
            "\n",
            "--- Meta-Generation 4 Results ---\n",
            "Best Operator Fitness (Avg Final Best): -11.3403\n",
            "Best Performing Operator's Code:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with adaptive diversity control.\n    - Elitism with cloning\n    - Adaptive tournament size\n    - Dynamic crossover strategy (Uniform / BLX-alpha)\n    - Adaptive Gaussian and reset mutation\n    - Immigrants injection when diversity is low\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Guard for degenerate populations\n    if POP_SIZE == 0:\n        return []\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    low_diversity = cv.item() < 0.05\n    unstable = cv.item() > 0.5\n\n    # --- Adaptive hyperparameters ---\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        TOURNAMENT_SIZE = 3\n        GAUSS_MUT_PROB = 0.02\n        GAUSS_SIGMA = 0.10\n        RESET_MUT_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.05\n        CROSSOVER_MODE = \"blx\"  # BLX-alpha crossover to expand search\n        BLX_ALPHA = 0.20\n    elif unstable:\n        ELITISM_RATE = 0.07\n        TOURNAMENT_SIZE = 7\n        GAUSS_MUT_PROB = 0.006\n        GAUSS_SIGMA = 0.03\n        RESET_MUT_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.01\n        CROSSOVER_MODE = \"uniform\"  # stabilize around good schemas\n        BLX_ALPHA = 0.10\n    else:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 5\n        GAUSS_MUT_PROB = 0.01\n        GAUSS_SIGMA = 0.05\n        RESET_MUT_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.02\n        CROSSOVER_MODE = \"mixed\"  # combine uniform and arithmetic\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        c = child.state_dict()\n\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = p1[k]\n                t2 = p2[k]\n                if CROSSOVER_MODE == \"uniform\":\n                    mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                    c[k] = t1 * mask + t2 * (1.0 - mask)\n                elif CROSSOVER_MODE == \"blx\":\n                    c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                else:  # mixed\n                    # 50% uniform mask, 50% arithmetic blend with per-element alpha in [0.25, 0.75]\n                    if torch.rand((), device=device) < 0.5:\n                        mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                        c[k] = t1 * mask + t2 * (1.0 - mask)\n                    else:\n                        alpha = 0.25 + 0.5 * torch.rand_like(t1)\n                        c[k] = alpha * t1 + (1.0 - alpha) * t2\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, gauss_prob=GAUSS_MUT_PROB, gauss_sigma=GAUSS_SIGMA, reset_prob=RESET_MUT_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if gauss_prob > 0.0:\n                    gmask = torch.rand_like(p) < gauss_prob\n                    noise = torch.randn_like(p) * gauss_sigma\n                    p[gmask] = p[gmask] + noise[gmask]\n                if reset_prob > 0.0:\n                    rmask = torch.rand_like(p) < reset_prob\n                    new_vals = torch.randn_like(p)\n                    p[rmask] = new_vals[rmask]\n        return model\n\n    def tournament_selection(population, scores_tensor, size=TOURNAMENT_SIZE):\n        idxs = torch.randint(0, len(population), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = int(idxs[torch.argmax(sub_scores)].item())\n        return population[winner_idx]\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = []\n    for i in range(num_elite):\n        elites.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    new_population = list(elites)\n\n    # Immigrants (fresh random individuals) for diversity\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        p1 = tournament_selection(current_population, scores)\n        # ensure different parents where possible\n        p2 = p1\n        attempts = 0\n        while p2 is p1 and attempts < 3:\n            p2 = tournament_selection(current_population, scores)\n            attempts += 1\n\n        child = crossover(p1, p2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if rounding errors occur, adjust size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # Fill up with additional mutated clones of elites\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            extra = clone_model(current_population[int(sorted_idx[i % len(sorted_idx)].item())])\n            new_population.append(mutate(extra))\n\n    return new_population\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Operator's Performance Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This operator's performance has been recorded over **3** separate runs.\nThe table below shows the fitness dynamics, **averaged across all runs**.\nFitness is based on the negative loss on training batches (higher is better).\n\n| Gen | Best Fitness | Avg Fitness  | Worst Fitness | Spread (Diversity) |\n|:---:|:------------:|:------------:|:-------------:|:------------------:|\n|  0  |     -11.4630 |     -11.5397 |      -11.6121 |             0.1491 |\n|  1  |     -11.4313 |     -11.5767 |      -12.1839 |             0.7526 |\n|  2  |     -11.4298 |     -11.5916 |      -11.9507 |             0.5209 |\n|  3  |     -11.3812 |     -11.6047 |      -11.9569 |             0.5757 |\n|  4  |     -11.3890 |     -11.6302 |      -12.2664 |             0.8774 |\n|  5  |     -11.3751 |     -11.6719 |      -13.6228 |             2.2477 |\n|  6  |     -11.3837 |     -11.6159 |      -12.1176 |             0.7339 |\n|  7  |     -11.3677 |     -11.6666 |      -12.3902 |             1.0226 |\n|  8  |     -11.3426 |     -11.6645 |      -12.4404 |             1.0978 |\n|  9  |     -11.3403 |     -11.6956 |      -13.2220 |             1.8817 |\n\n**Analysis Hints for Your Evolution:**\n- **Rate of Improvement:** Analyze the slope of the `Best Fitness` column. A steep, consistent increase is ideal.\n- **Population Diversity:** The `Spread (Best-Worst)` column is a proxy for diversity. If it collapses to near-zero too quickly, the population has prematurely converged, and you should consider changes that increase exploration (e.g., higher mutation, different selection).\n- **Stability:** Smooth, predictable improvements indicate a stable operator. Jagged or erratic values might suggest the operator is too chaotic."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Calling Google API to evolve operator (with generational feedback) ---\n",
            "--- Calling Openai API to evolve operator (with generational feedback) ---\n",
            "\n",
            "Meta-Evolution finished!\n",
            "Final Best Performing Operator:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Overall Fitness (Avg Final Best): -11.3403\nEvaluated over 3 runs.\n--- Operator Code ---\ndef generate_next_population(current_population, fitness_scores, device, torch, SimpleNet):\n    \"\"\"\n    Holistic evolutionary operator with adaptive diversity control.\n    - Elitism with cloning\n    - Adaptive tournament size\n    - Dynamic crossover strategy (Uniform / BLX-alpha)\n    - Adaptive Gaussian and reset mutation\n    - Immigrants injection when diversity is low\n    \"\"\"\n    POP_SIZE = len(current_population)\n\n    # --- Prepare fitness tensor ---\n    scores = fitness_scores\n    if not torch.is_tensor(scores):\n        scores = torch.tensor(scores, dtype=torch.float32, device=device)\n    else:\n        scores = scores.to(device=device, dtype=torch.float32)\n\n    # Guard for degenerate populations\n    if POP_SIZE == 0:\n        return []\n\n    # --- Diversity diagnostics (coefficient of variation) ---\n    mean = torch.mean(scores)\n    std = torch.std(scores)\n    cv = std / (torch.abs(mean) + 1e-8)\n\n    low_diversity = cv.item() < 0.05\n    unstable = cv.item() > 0.5\n\n    # --- Adaptive hyperparameters ---\n    if low_diversity:\n        ELITISM_RATE = 0.08\n        TOURNAMENT_SIZE = 3\n        GAUSS_MUT_PROB = 0.02\n        GAUSS_SIGMA = 0.10\n        RESET_MUT_PROB = 5e-4\n        IMMIGRANTS_RATE = 0.05\n        CROSSOVER_MODE = \"blx\"  # BLX-alpha crossover to expand search\n        BLX_ALPHA = 0.20\n    elif unstable:\n        ELITISM_RATE = 0.07\n        TOURNAMENT_SIZE = 7\n        GAUSS_MUT_PROB = 0.006\n        GAUSS_SIGMA = 0.03\n        RESET_MUT_PROB = 1e-5\n        IMMIGRANTS_RATE = 0.01\n        CROSSOVER_MODE = \"uniform\"  # stabilize around good schemas\n        BLX_ALPHA = 0.10\n    else:\n        ELITISM_RATE = 0.10\n        TOURNAMENT_SIZE = 5\n        GAUSS_MUT_PROB = 0.01\n        GAUSS_SIGMA = 0.05\n        RESET_MUT_PROB = 1e-4\n        IMMIGRANTS_RATE = 0.02\n        CROSSOVER_MODE = \"mixed\"  # combine uniform and arithmetic\n\n    num_elite = max(1, int(POP_SIZE * ELITISM_RATE))\n    num_immigrants = max(0, int(POP_SIZE * IMMIGRANTS_RATE))\n    num_children = POP_SIZE - num_elite - num_immigrants\n\n    # --- Utilities ---\n    def clone_model(model):\n        m = SimpleNet().to(device)\n        m.load_state_dict(model.state_dict())\n        return m\n\n    def blx_alpha_tensor(p1, p2, alpha):\n        low = torch.minimum(p1, p2)\n        high = torch.maximum(p1, p2)\n        span = high - low\n        minv = low - alpha * span\n        maxv = high + alpha * span\n        return minv + (maxv - minv) * torch.rand_like(p1)\n\n    def crossover(parent1, parent2):\n        child = SimpleNet().to(device)\n        p1 = parent1.state_dict()\n        p2 = parent2.state_dict()\n        c = child.state_dict()\n\n        with torch.no_grad():\n            for k in c.keys():\n                t1 = p1[k]\n                t2 = p2[k]\n                if CROSSOVER_MODE == \"uniform\":\n                    mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                    c[k] = t1 * mask + t2 * (1.0 - mask)\n                elif CROSSOVER_MODE == \"blx\":\n                    c[k] = blx_alpha_tensor(t1, t2, BLX_ALPHA)\n                else:  # mixed\n                    # 50% uniform mask, 50% arithmetic blend with per-element alpha in [0.25, 0.75]\n                    if torch.rand((), device=device) < 0.5:\n                        mask = (torch.rand_like(t1) < 0.5).to(t1.dtype)\n                        c[k] = t1 * mask + t2 * (1.0 - mask)\n                    else:\n                        alpha = 0.25 + 0.5 * torch.rand_like(t1)\n                        c[k] = alpha * t1 + (1.0 - alpha) * t2\n        child.load_state_dict(c)\n        return child\n\n    def mutate(model, gauss_prob=GAUSS_MUT_PROB, gauss_sigma=GAUSS_SIGMA, reset_prob=RESET_MUT_PROB):\n        with torch.no_grad():\n            for p in model.parameters():\n                if gauss_prob > 0.0:\n                    gmask = torch.rand_like(p) < gauss_prob\n                    noise = torch.randn_like(p) * gauss_sigma\n                    p[gmask] = p[gmask] + noise[gmask]\n                if reset_prob > 0.0:\n                    rmask = torch.rand_like(p) < reset_prob\n                    new_vals = torch.randn_like(p)\n                    p[rmask] = new_vals[rmask]\n        return model\n\n    def tournament_selection(population, scores_tensor, size=TOURNAMENT_SIZE):\n        idxs = torch.randint(0, len(population), (size,), device=device)\n        sub_scores = scores_tensor[idxs]\n        winner_idx = int(idxs[torch.argmax(sub_scores)].item())\n        return population[winner_idx]\n\n    # --- Build next population ---\n    sorted_idx = torch.argsort(scores, descending=True)\n    elites = []\n    for i in range(num_elite):\n        elites.append(clone_model(current_population[int(sorted_idx[i].item())]))\n\n    new_population = list(elites)\n\n    # Immigrants (fresh random individuals) for diversity\n    for _ in range(num_immigrants):\n        new_population.append(SimpleNet().to(device))\n\n    # Children via selection, crossover, mutation\n    for _ in range(num_children):\n        p1 = tournament_selection(current_population, scores)\n        # ensure different parents where possible\n        p2 = p1\n        attempts = 0\n        while p2 is p1 and attempts < 3:\n            p2 = tournament_selection(current_population, scores)\n            attempts += 1\n\n        child = crossover(p1, p2)\n        child = mutate(child)\n        new_population.append(child)\n\n    # Safety: if rounding errors occur, adjust size\n    if len(new_population) > POP_SIZE:\n        new_population = new_population[:POP_SIZE]\n    elif len(new_population) < POP_SIZE:\n        # Fill up with additional mutated clones of elites\n        fill_needed = POP_SIZE - len(new_population)\n        for i in range(fill_needed):\n            extra = clone_model(current_population[int(sorted_idx[i % len(sorted_idx)].item())])\n            new_population.append(mutate(extra))\n\n    return new_population"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
